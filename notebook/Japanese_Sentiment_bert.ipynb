{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-16T13:27:53.708355Z",
     "iopub.status.busy": "2025-06-16T13:27:53.708128Z",
     "iopub.status.idle": "2025-06-16T13:28:07.235675Z",
     "shell.execute_reply": "2025-06-16T13:28:07.234545Z",
     "shell.execute_reply.started": "2025-06-16T13:27:53.708334Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ========================\n",
    "# 0. Install libraries\n",
    "# ========================\n",
    "!pip install --quiet numpy spacy thinc\n",
    "!pip install --quiet torch torchvision torchaudio\n",
    "!pip install --quiet transformers fugashi ipadic accelerate peft sentencepiece matplotlib seaborn tqdm\n",
    "!pip install --quiet xgboost optuna ace_tools_open shap unidic-lite mecab-python3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-06-16T13:28:07.237234Z",
     "iopub.status.busy": "2025-06-16T13:28:07.236876Z",
     "iopub.status.idle": "2025-06-16T13:28:07.242356Z",
     "shell.execute_reply": "2025-06-16T13:28:07.241437Z",
     "shell.execute_reply.started": "2025-06-16T13:28:07.237202Z"
    },
    "executionInfo": {
     "elapsed": 11956,
     "status": "ok",
     "timestamp": 1749745839913,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -120
    },
    "id": "dfTjYNifrfFP",
    "outputId": "e7cb8ee5-9510-42b7-800f-2808e2fd5f23",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "print(\"CUDA available:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-06-16T13:28:08.283073Z",
     "iopub.status.busy": "2025-06-16T13:28:08.282801Z",
     "iopub.status.idle": "2025-06-16T13:28:08.287097Z",
     "shell.execute_reply": "2025-06-16T13:28:08.286419Z",
     "shell.execute_reply.started": "2025-06-16T13:28:08.283053Z"
    },
    "executionInfo": {
     "elapsed": 5942,
     "status": "ok",
     "timestamp": 1749745845854,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -120
    },
    "id": "7Nr0KW0ZiCea",
    "outputId": "59410d81-c86a-4a5b-d5a3-a9f0d0cc9a7a",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-06-16T13:28:08.290079Z",
     "iopub.status.busy": "2025-06-16T13:28:08.289810Z",
     "iopub.status.idle": "2025-06-16T13:28:14.983267Z",
     "shell.execute_reply": "2025-06-16T13:28:14.981970Z",
     "shell.execute_reply.started": "2025-06-16T13:28:08.290051Z"
    },
    "executionInfo": {
     "elapsed": 19046,
     "status": "ok",
     "timestamp": 1749745864901,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -120
    },
    "id": "7TK8QWC8kvZa",
    "outputId": "ae8ac29b-aad2-4f64-d6cb-e0d0056a38c5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install certifi\n",
    "!mkdir -p /usr/local/share/ca-certificates/\n",
    "!cp /etc/ssl/certs/ca-certificates.crt /usr/local/share/ca-certificates/\n",
    "!update-ca-certificates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 926,
     "referenced_widgets": [
      "6b729dbc1b204303b12d44def92e5af9",
      "0913fa97ccd74ef49a00ee04b63ea6bf",
      "9598dbe3b1c64dadad37002cd73a81cf",
      "602c48c5116141109cbd7bdd4b76544a",
      "ec7ec7303f8c4284871fd36e628db99f",
      "8b53bd89d0b34ddaae3115a653e0d775",
      "59aa76f235764770b2382ee79efeb575",
      "bdd7f2df67c54ba3a31c859984b9a8ac",
      "557028e8e3a7418d913b0eafc59a4e99",
      "a4a95fd3ca1a48bd8a7886f46b7d2410",
      "a4df42534a4f42f4adb067d25838788a",
      "ef972f5ca5d3454b857849a9fa1df2a6",
      "47fa45983dca46de914fb882917a8422",
      "ef404e26e95f4fc6b5d3e46e07daab96",
      "ebdcfad4799d498b99a4ebfe98819aa3",
      "762858486a7b4858b9bdc025219a169f",
      "da2bdb8ad23c4ecbb0f3dadc569a5b55",
      "81169d8b554a4e9aa65eed52538bb0f0",
      "44a143b60fd1446cb35dbe21d5de0bf4",
      "ffb4d6bc88bf4b14a325ff9a2fc154e0",
      "25233e339a77418a846f7ed7dbc906c0",
      "12ec674eff1d4989955fcbed87554ffd",
      "a2fa6d052cc54e94a8a4d8be7d18b3ee",
      "8e673ea2d9e44aad83d83fdee8e1eed6",
      "27fca39b431c48c394fdb434760570d0",
      "18cd81a4ce594285ab1081fa723f005a",
      "55f3c34729de4f01a1b8245ee5723220",
      "af0c0d8edbec4611bf611d2ac4b85c1c",
      "d4de67040a2942ebad27e94be89778b2",
      "94103ec6f7364f54a10460fcaa83713c",
      "19aa71867f6f42a88e6bbe811b354e30",
      "aa8acb1f146642ca9446be325ffc9e31",
      "708c6c94c066489081ad8875d00e3b51"
     ]
    },
    "execution": {
     "iopub.execute_input": "2025-06-16T13:28:14.985196Z",
     "iopub.status.busy": "2025-06-16T13:28:14.984911Z",
     "iopub.status.idle": "2025-06-16T13:33:13.919215Z",
     "shell.execute_reply": "2025-06-16T13:33:13.918359Z",
     "shell.execute_reply.started": "2025-06-16T13:28:14.985164Z"
    },
    "executionInfo": {
     "elapsed": 33625,
     "status": "error",
     "timestamp": 1749745898528,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -120
    },
    "id": "mMxTA1g2UHy6",
    "outputId": "d8bd9a0f-ec7a-4ee6-80f3-0980744bcdc9",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ========================\n",
    "# 1. Imports & Setup\n",
    "# ========================\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModel\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "from sklearn.preprocessing import LabelEncoder, label_binarize\n",
    "import optuna\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "try:\n",
    "    from ace_tools_open import display_dataframe_to_user\n",
    "except ImportError:\n",
    "    def display_dataframe_to_user(*args, **kwargs):\n",
    "        print(\"ace_tools not installed; displaying DataFrame head:\")\n",
    "        print(args[1].head())\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# ========================\n",
    "# 2. Kansai-ben & Directness Detection\n",
    "# ========================\n",
    "kansaiben_keywords = [\"„Äú„ÇÑ„Çì\", \"„Äú„ÇÑ„Åß\", \"„Äú„Åõ„Å™„ÅÇ„Åã„Çì\", \"„Å°„ÇÉ„ÅÜ\", \"„Åª„Çì„Åæ\", \"„ÇÅ„Å£„Å°„ÇÉ\", \"„Äú„Åõ„Çì„Å®\", \"„Å™„Çì„Åß„ÇÑ„Å≠„Çì\"]\n",
    "def detect_kansaiben(text):\n",
    "    return any(k in text for k in kansaiben_keywords)\n",
    "\n",
    "def detect_directness(text):\n",
    "    direct_phrases = [\"ÊúÄÊÇ™\", \"„ÅÇ„Çä„Åà„Å™„ÅÑ\", \"„ÇÅ„Å£„Å°„ÇÉ\", \"„Å†„ÇÅ\", \"ËâØ„ÅÑ\", \"ËâØ„Åè„Å™„ÅÑ\", \"„Åä„Åô„Åô„ÇÅ\", \"Áµ∂ÂØæ\", \"ÂæÆÂ¶ô\"]\n",
    "    return any(word in text for word in direct_phrases)\n",
    "\n",
    "# ========================\n",
    "# 3. Load & Prepare Data (CHUNKED)\n",
    "# ========================\n",
    "def load_jsts_json(url):\n",
    "    df = pd.read_json(url, lines=True)\n",
    "    df['text'] = df['sentence1'] + \" \" + df['sentence2']\n",
    "    df['sentiment'] = df['label'].apply(lambda x: 0 if x < 2 else (1 if x <= 3 else 2))\n",
    "    return df[['text', 'sentiment']]\n",
    "\n",
    "train_url = \"https://raw.githubusercontent.com/yahoojapan/JGLUE/refs/heads/main/datasets/jsts-v1.3/train-v1.3.json\"\n",
    "valid_url = \"https://raw.githubusercontent.com/yahoojapan/JGLUE/refs/heads/main/datasets/jsts-v1.3/valid-v1.3.json\"\n",
    "test_url  = \"https://raw.githubusercontent.com/yahoojapan/JGLUE/refs/heads/main/datasets/jsts-v1.3/test-v1.3.json\"\n",
    "\n",
    "chunk_size = 800   # For low GPU RAM; adjust up if you have more memory\n",
    "\n",
    "df_valid = load_jsts_json(valid_url).sample(500, random_state=42)\n",
    "df_test = load_jsts_json(test_url).sample(100, random_state=42)\n",
    "\n",
    "model_name = \"cl-tohoku/bert-base-japanese-v2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenize_batch(texts):\n",
    "    return tokenizer(list(texts), truncation=True, padding=\"max_length\", max_length=128, return_tensors='pt')\n",
    "\n",
    "class SimpleDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.encodings = tokenize_batch(df['text'])\n",
    "        self.labels = torch.tensor(df['sentiment'].values)\n",
    "    def __getitem__(self, idx):\n",
    "        item = {k: v[idx] for k, v in self.encodings.items()}\n",
    "        item[\"labels\"] = self.labels[idx]\n",
    "        return item\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# ========================\n",
    "# 4. LoRA Model Init & Batch Finetune (demonstration)\n",
    "# ========================\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)\n",
    "peft_config = LoraConfig(task_type=TaskType.SEQ_CLS, r=8, lora_alpha=16, lora_dropout=0.1, bias=\"none\")\n",
    "model = get_peft_model(base_model, peft_config).to(device)\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "\n",
    "for i, df_chunk in enumerate(pd.read_json(train_url, lines=True, chunksize=chunk_size)):\n",
    "    df_chunk = df_chunk.sample(frac=1, random_state=42+i).reset_index(drop=True)\n",
    "    df_chunk['text'] = df_chunk['sentence1'] + \" \" + df_chunk['sentence2']\n",
    "    df_chunk['sentiment'] = df_chunk['label'].apply(lambda x: 0 if x < 2 else (1 if x <= 3 else 2))\n",
    "    df_chunk = df_chunk[['text', 'sentiment']]\n",
    "    train_ds = SimpleDataset(df_chunk)\n",
    "    train_loader = DataLoader(train_ds, batch_size=8, shuffle=True)\n",
    "    optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "    model.train()\n",
    "    for epoch in range(1):  # For demonstration, 1 epoch per chunk\n",
    "        loop = tqdm(train_loader, desc=f\"Training chunk {i+1}\")\n",
    "        for batch in loop:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            loop.set_postfix(loss=loss.item())\n",
    "\n",
    "# ========================\n",
    "# 5. Extract Transformer [CLS] Embeddings (All Sets, in Batches)\n",
    "# ========================\n",
    "bert_encoder = AutoModel.from_pretrained(model_name).to(device)\n",
    "bert_encoder.eval()\n",
    "\n",
    "def extract_cls_embeddings_batched(encoder, texts, tokenizer, device, batch_size=32):\n",
    "    embeddings = []\n",
    "    n = len(texts)\n",
    "    for i in tqdm(range(0, n, batch_size), desc=\"Extracting embeddings\"):\n",
    "        batch_texts = texts.iloc[i:i+batch_size]\n",
    "        inputs = tokenizer(list(batch_texts), return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=128).to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = encoder(**inputs)\n",
    "        batch_emb = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "        embeddings.append(batch_emb)\n",
    "    return np.vstack(embeddings)\n",
    "\n",
    "valid_embeddings = extract_cls_embeddings_batched(bert_encoder, df_valid['text'], tokenizer, device, batch_size=32)\n",
    "test_embeddings = extract_cls_embeddings_batched(bert_encoder, df_test['text'], tokenizer, device, batch_size=32)\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_valid = le.fit_transform(df_valid['sentiment'])\n",
    "y_test = le.transform(df_test['sentiment'])\n",
    "\n",
    "# ========================\n",
    "# 6. Add Classical Features to Test Set\n",
    "# ========================\n",
    "df_test['length'] = df_test['text'].apply(len)\n",
    "df_test['kansai_ben'] = df_test['text'].apply(detect_kansaiben).astype(int)\n",
    "df_test['direct_tone'] = df_test['text'].apply(detect_directness).astype(int)\n",
    "classic_feats_test = df_test[['length', 'kansai_ben', 'direct_tone']].values\n",
    "combined_test_features = np.hstack([test_embeddings, classic_feats_test])\n",
    "\n",
    "df_valid['length'] = df_valid['text'].apply(len)\n",
    "df_valid['kansai_ben'] = df_valid['text'].apply(detect_kansaiben).astype(int)\n",
    "df_valid['direct_tone'] = df_valid['text'].apply(detect_directness).astype(int)\n",
    "classic_feats_valid = df_valid[['length', 'kansai_ben', 'direct_tone']].values\n",
    "combined_valid_features = np.hstack([valid_embeddings, classic_feats_valid])\n",
    "\n",
    "# ========================\n",
    "# 7. Optuna + K-Fold CV for XGBoost (validation only, with classic features)\n",
    "# ========================\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 150),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 5),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.15, log=True),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0, 2),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0, 0.5),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0, 0.5),\n",
    "        \"use_label_encoder\": False,\n",
    "        \"eval_metric\": \"mlogloss\",\n",
    "        \"verbosity\": 0,\n",
    "        \"tree_method\": \"gpu_hist\",\n",
    "    }\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    scores = []\n",
    "    for train_idx, valid_idx in skf.split(combined_valid_features, y_valid):\n",
    "        X_tr, X_va = combined_valid_features[train_idx], combined_valid_features[valid_idx]\n",
    "        y_tr, y_va = y_valid[train_idx], y_valid[valid_idx]\n",
    "        clf = XGBClassifier(**params)\n",
    "        clf.fit(X_tr, y_tr)\n",
    "        preds = clf.predict(X_va)\n",
    "        score = np.mean(preds == y_va)\n",
    "        scores.append(score)\n",
    "    return np.mean(scores)\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=8)\n",
    "print(\"Best trial:\", study.best_trial.params)\n",
    "\n",
    "# ========================\n",
    "# 8. Fit Final XGBoost on Validation, Evaluate on Test (with classic features)\n",
    "# ========================\n",
    "feat_names = np.array([f'CLS_emb_{i}' for i in range(test_embeddings.shape[1])] + ['length', 'kansai_ben', 'direct_tone'])\n",
    "clf = XGBClassifier(**study.best_trial.params)\n",
    "clf.fit(combined_valid_features, y_valid)\n",
    "test_pred = clf.predict(combined_test_features)\n",
    "df_test['xgb_pred'] = le.inverse_transform(test_pred)\n",
    "test_pred_proba = clf.predict_proba(combined_test_features)\n",
    "\n",
    "print(\"\\nClassification Report (XGBoost + Optuna, Test Set):\")\n",
    "print(classification_report(df_test['sentiment'], df_test['xgb_pred']))\n",
    "\n",
    "# ========================\n",
    "# 9. Confusion Matrix (Test)\n",
    "# ========================\n",
    "plt.figure(figsize=(6,5))\n",
    "cm = confusion_matrix(df_test['sentiment'], df_test['xgb_pred'])\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix (Test Set)\")\n",
    "plt.show()\n",
    "\n",
    "# ========================\n",
    "# 10. AUC-ROC Curve (Test, One-vs-Rest)\n",
    "# ========================\n",
    "y_test_bin = label_binarize(df_test['sentiment'], classes=[0,1,2])\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "n_classes = y_test_bin.shape[1]\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], test_pred_proba[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "for i in range(n_classes):\n",
    "    plt.plot(fpr[i], tpr[i], label=f\"Class {le.classes_[i]} (AUC = {roc_auc[i]:.2f})\")\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"AUC-ROC Curve (Test Set, OvR)\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# ========================\n",
    "# 11. Stakeholder-Ready Feature Importance & SHAP (FIXED)\n",
    "# ========================\n",
    "explainer = shap.Explainer(clf, combined_test_features)\n",
    "shap_values = explainer(combined_test_features)\n",
    "\n",
    "# --- Stakeholder Bar Plot: Only classic features (last three) ---\n",
    "classic_idxs = [-3, -2, -1]  # length, kansai_ben, direct_tone\n",
    "classic_names = feat_names[classic_idxs]\n",
    "\n",
    "# FIX: For multiclass, SHAP values are 3D (n_samples, n_features, n_classes)\n",
    "# We need to take mean across samples AND classes to get feature importance\n",
    "if len(shap_values.values.shape) == 3:\n",
    "    # Multiclass case: take mean across samples (axis=0) and classes (axis=2)\n",
    "    classic_importance = np.abs(shap_values.values).mean(axis=(0, 2))[classic_idxs]\n",
    "else:\n",
    "    # Binary case: take mean across samples only\n",
    "    classic_importance = np.abs(shap_values.values).mean(axis=0)[classic_idxs]\n",
    "\n",
    "classic_importance = np.array(classic_importance, dtype=float).flatten()\n",
    "y_pos = np.arange(len(classic_names))\n",
    "\n",
    "# Ensure we have enough colors\n",
    "color_list = ['#62b5e5', '#a2d4ab', '#fa7268']\n",
    "colors = (color_list * ((len(classic_names)+2)//3))[:len(classic_names)]\n",
    "\n",
    "print(f\"Debug: classic_names shape: {classic_names.shape}\")\n",
    "print(f\"Debug: classic_importance shape: {classic_importance.shape}\")\n",
    "print(f\"Debug: colors length: {len(colors)}\")\n",
    "\n",
    "plt.figure(figsize=(7,2))\n",
    "plt.barh(y_pos, classic_importance, color=colors)\n",
    "plt.yticks(y_pos, classic_names)\n",
    "plt.xlabel(\"Mean absolute SHAP value\")\n",
    "plt.title(\"Top Interpretability Features (Stakeholder View)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- Table for slides/exports ---\n",
    "df_shap = pd.DataFrame({\n",
    "    \"Feature\": classic_names,\n",
    "    \"Mean_abs_SHAP\": classic_importance\n",
    "})\n",
    "print(\"\\nFeature Importance Summary:\")\n",
    "print(df_shap)\n",
    "\n",
    "# --- Optional: SHAP Waterfall for one test prediction (explains an example)\n",
    "try:\n",
    "    shap.plots.waterfall(shap_values[0], max_display=5, feature_names=feat_names)\n",
    "except Exception as e:\n",
    "    print(f\"Waterfall plot failed: {e}\")\n",
    "    print(\"This is common with multiclass SHAP - you can use summary plots instead\")\n",
    "\n",
    "# Alternative: SHAP Summary Plot (works better with multiclass)\n",
    "plt.figure(figsize=(8, 6))\n",
    "shap.summary_plot(shap_values.values[:, classic_idxs], \n",
    "                  combined_test_features[:, classic_idxs], \n",
    "                  feature_names=classic_names, \n",
    "                  show=False)\n",
    "plt.title(\"SHAP Summary Plot - Classic Features\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ========================\n",
    "# 12. Display Results (Test)\n",
    "# ========================\n",
    "display_dataframe_to_user(name=\"JGLUE Sentiment + Kansai-ben Analysis (Test Set)\", dataframe=df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-16T13:34:21.251156Z",
     "iopub.status.busy": "2025-06-16T13:34:21.250807Z",
     "iopub.status.idle": "2025-06-16T13:38:35.254524Z",
     "shell.execute_reply": "2025-06-16T13:38:35.253674Z",
     "shell.execute_reply.started": "2025-06-16T13:34:21.251132Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ========================\n",
    "# 1. Imports & Setup\n",
    "# ========================\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModel\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "from sklearn.preprocessing import LabelEncoder, label_binarize\n",
    "import optuna\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "try:\n",
    "    from ace_tools_open import display_dataframe_to_user\n",
    "except ImportError:\n",
    "    def display_dataframe_to_user(*args, **kwargs):\n",
    "        print(\"ace_tools not installed; displaying DataFrame head:\")\n",
    "        print(args[1].head())\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# ========================\n",
    "# 2. Kansai-ben & Directness Detection\n",
    "# ========================\n",
    "kansaiben_keywords = [\"„Äú„ÇÑ„Çì\", \"„Äú„ÇÑ„Åß\", \"„Äú„Åõ„Å™„ÅÇ„Åã„Çì\", \"„Å°„ÇÉ„ÅÜ\", \"„Åª„Çì„Åæ\", \"„ÇÅ„Å£„Å°„ÇÉ\", \"„Äú„Åõ„Çì„Å®\", \"„Å™„Çì„Åß„ÇÑ„Å≠„Çì\"]\n",
    "def detect_kansaiben(text):\n",
    "    return any(k in text for k in kansaiben_keywords)\n",
    "\n",
    "def detect_directness(text):\n",
    "    direct_phrases = [\"ÊúÄÊÇ™\", \"„ÅÇ„Çä„Åà„Å™„ÅÑ\", \"„ÇÅ„Å£„Å°„ÇÉ\", \"„Å†„ÇÅ\", \"ËâØ„ÅÑ\", \"ËâØ„Åè„Å™„ÅÑ\", \"„Åä„Åô„Åô„ÇÅ\", \"Áµ∂ÂØæ\", \"ÂæÆÂ¶ô\"]\n",
    "    return any(word in text for word in direct_phrases)\n",
    "\n",
    "# ========================\n",
    "# 3. Load & Prepare Data (CHUNKED)\n",
    "# ========================\n",
    "def load_jsts_json(url):\n",
    "    df = pd.read_json(url, lines=True)\n",
    "    df['text'] = df['sentence1'] + \" \" + df['sentence2']\n",
    "    df['sentiment'] = df['label'].apply(lambda x: 0 if x < 2 else (1 if x <= 3 else 2))\n",
    "    return df[['text', 'sentiment']]\n",
    "\n",
    "train_url = \"https://raw.githubusercontent.com/yahoojapan/JGLUE/refs/heads/main/datasets/jsts-v1.3/train-v1.3.json\"\n",
    "valid_url = \"https://raw.githubusercontent.com/yahoojapan/JGLUE/refs/heads/main/datasets/jsts-v1.3/valid-v1.3.json\"\n",
    "test_url  = \"https://raw.githubusercontent.com/yahoojapan/JGLUE/refs/heads/main/datasets/jsts-v1.3/test-v1.3.json\"\n",
    "\n",
    "chunk_size = 800   # For low GPU RAM; adjust up if you have more memory\n",
    "\n",
    "df_valid = load_jsts_json(valid_url).sample(500, random_state=42)\n",
    "df_test = load_jsts_json(test_url).sample(100, random_state=42)\n",
    "\n",
    "model_name = \"cl-tohoku/bert-base-japanese-v2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenize_batch(texts):\n",
    "    return tokenizer(list(texts), truncation=True, padding=\"max_length\", max_length=128, return_tensors='pt')\n",
    "\n",
    "class SimpleDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.encodings = tokenize_batch(df['text'])\n",
    "        self.labels = torch.tensor(df['sentiment'].values)\n",
    "    def __getitem__(self, idx):\n",
    "        item = {k: v[idx] for k, v in self.encodings.items()}\n",
    "        item[\"labels\"] = self.labels[idx]\n",
    "        return item\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# ========================\n",
    "# 4. LoRA Model Init & Batch Finetune (demonstration)\n",
    "# ========================\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)\n",
    "peft_config = LoraConfig(task_type=TaskType.SEQ_CLS, r=8, lora_alpha=16, lora_dropout=0.1, bias=\"none\")\n",
    "model = get_peft_model(base_model, peft_config).to(device)\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "\n",
    "for i, df_chunk in enumerate(pd.read_json(train_url, lines=True, chunksize=chunk_size)):\n",
    "    df_chunk = df_chunk.sample(frac=1, random_state=42+i).reset_index(drop=True)\n",
    "    df_chunk['text'] = df_chunk['sentence1'] + \" \" + df_chunk['sentence2']\n",
    "    df_chunk['sentiment'] = df_chunk['label'].apply(lambda x: 0 if x < 2 else (1 if x <= 3 else 2))\n",
    "    df_chunk = df_chunk[['text', 'sentiment']]\n",
    "    train_ds = SimpleDataset(df_chunk)\n",
    "    train_loader = DataLoader(train_ds, batch_size=8, shuffle=True)\n",
    "    optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "    model.train()\n",
    "    for epoch in range(1):  # For demonstration, 1 epoch per chunk\n",
    "        loop = tqdm(train_loader, desc=f\"Training chunk {i+1}\")\n",
    "        for batch in loop:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            loop.set_postfix(loss=loss.item())\n",
    "\n",
    "# ========================\n",
    "# 5. Extract Transformer [CLS] Embeddings (All Sets, in Batches)\n",
    "# ========================\n",
    "bert_encoder = AutoModel.from_pretrained(model_name).to(device)\n",
    "bert_encoder.eval()\n",
    "\n",
    "def extract_cls_embeddings_batched(encoder, texts, tokenizer, device, batch_size=32):\n",
    "    embeddings = []\n",
    "    n = len(texts)\n",
    "    for i in tqdm(range(0, n, batch_size), desc=\"Extracting embeddings\"):\n",
    "        batch_texts = texts.iloc[i:i+batch_size]\n",
    "        inputs = tokenizer(list(batch_texts), return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=128).to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = encoder(**inputs)\n",
    "        batch_emb = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "        embeddings.append(batch_emb)\n",
    "    return np.vstack(embeddings)\n",
    "\n",
    "valid_embeddings = extract_cls_embeddings_batched(bert_encoder, df_valid['text'], tokenizer, device, batch_size=32)\n",
    "test_embeddings = extract_cls_embeddings_batched(bert_encoder, df_test['text'], tokenizer, device, batch_size=32)\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_valid = le.fit_transform(df_valid['sentiment'])\n",
    "y_test = le.transform(df_test['sentiment'])\n",
    "\n",
    "# ========================\n",
    "# 6. Add Classical Features to Test Set\n",
    "# ========================\n",
    "df_test['length'] = df_test['text'].apply(len)\n",
    "df_test['kansai_ben'] = df_test['text'].apply(detect_kansaiben).astype(int)\n",
    "df_test['direct_tone'] = df_test['text'].apply(detect_directness).astype(int)\n",
    "classic_feats_test = df_test[['length', 'kansai_ben', 'direct_tone']].values\n",
    "combined_test_features = np.hstack([test_embeddings, classic_feats_test])\n",
    "\n",
    "df_valid['length'] = df_valid['text'].apply(len)\n",
    "df_valid['kansai_ben'] = df_valid['text'].apply(detect_kansaiben).astype(int)\n",
    "df_valid['direct_tone'] = df_valid['text'].apply(detect_directness).astype(int)\n",
    "classic_feats_valid = df_valid[['length', 'kansai_ben', 'direct_tone']].values\n",
    "combined_valid_features = np.hstack([valid_embeddings, classic_feats_valid])\n",
    "\n",
    "# ========================\n",
    "# 7. Optuna + K-Fold CV for XGBoost (validation only, with classic features)\n",
    "# ========================\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 150),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 5),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.15, log=True),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0, 2),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0, 0.5),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0, 0.5),\n",
    "        \"use_label_encoder\": False,\n",
    "        \"eval_metric\": \"mlogloss\",\n",
    "        \"verbosity\": 0,\n",
    "        \"tree_method\": \"gpu_hist\",\n",
    "    }\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    scores = []\n",
    "    for train_idx, valid_idx in skf.split(combined_valid_features, y_valid):\n",
    "        X_tr, X_va = combined_valid_features[train_idx], combined_valid_features[valid_idx]\n",
    "        y_tr, y_va = y_valid[train_idx], y_valid[valid_idx]\n",
    "        clf = XGBClassifier(**params)\n",
    "        clf.fit(X_tr, y_tr)\n",
    "        preds = clf.predict(X_va)\n",
    "        score = np.mean(preds == y_va)\n",
    "        scores.append(score)\n",
    "    return np.mean(scores)\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=8)\n",
    "print(\"Best trial:\", study.best_trial.params)\n",
    "\n",
    "# ========================\n",
    "# 8. Fit Final XGBoost on Validation, Evaluate on Test (with classic features)\n",
    "# ========================\n",
    "feat_names = np.array([f'CLS_emb_{i}' for i in range(test_embeddings.shape[1])] + ['length', 'kansai_ben', 'direct_tone'])\n",
    "clf = XGBClassifier(**study.best_trial.params)\n",
    "clf.fit(combined_valid_features, y_valid)\n",
    "test_pred = clf.predict(combined_test_features)\n",
    "df_test['xgb_pred'] = le.inverse_transform(test_pred)\n",
    "test_pred_proba = clf.predict_proba(combined_test_features)\n",
    "\n",
    "print(\"\\nClassification Report (XGBoost + Optuna, Test Set):\")\n",
    "print(classification_report(df_test['sentiment'], df_test['xgb_pred']))\n",
    "\n",
    "# ========================\n",
    "# 9. Confusion Matrix (Test)\n",
    "# ========================\n",
    "plt.figure(figsize=(6,5))\n",
    "cm = confusion_matrix(df_test['sentiment'], df_test['xgb_pred'])\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix (Test Set)\")\n",
    "plt.show()\n",
    "\n",
    "# ========================\n",
    "# 10. AUC-ROC Curve (Test, One-vs-Rest)\n",
    "# ========================\n",
    "y_test_bin = label_binarize(df_test['sentiment'], classes=[0,1,2])\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "n_classes = y_test_bin.shape[1]\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], test_pred_proba[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "for i in range(n_classes):\n",
    "    plt.plot(fpr[i], tpr[i], label=f\"Class {le.classes_[i]} (AUC = {roc_auc[i]:.2f})\")\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"AUC-ROC Curve (Test Set, OvR)\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# ========================\n",
    "# 11. Stakeholder-Friendly Feature Importance Analysis\n",
    "# ========================\n",
    "\n",
    "# Get feature importance from XGBoost directly (simpler alternative to SHAP)\n",
    "feature_importance_xgb = clf.feature_importances_\n",
    "classic_idxs = [-3, -2, -1]  # length, kansai_ben, direct_tone\n",
    "classic_names = feat_names[classic_idxs]\n",
    "classic_importance = feature_importance_xgb[classic_idxs]\n",
    "\n",
    "# Alternative: Use SHAP if you want more sophisticated explanations\n",
    "# explainer = shap.Explainer(clf, combined_test_features)\n",
    "# shap_values = explainer(combined_test_features)\n",
    "# if len(shap_values.values.shape) == 3:\n",
    "#     classic_importance = np.abs(shap_values.values).mean(axis=(0, 2))[classic_idxs]\n",
    "# else:\n",
    "#     classic_importance = np.abs(shap_values.values).mean(axis=0)[classic_idxs]\n",
    "\n",
    "# ========================\n",
    "# STAKEHOLDER-FRIENDLY VISUALIZATIONS\n",
    "# ========================\n",
    "\n",
    "def create_business_impact_chart(classic_names, classic_importance):\n",
    "    \"\"\"Clean, professional chart showing business impact of each feature\"\"\"\n",
    "    business_labels = {\n",
    "        'length': 'Text Length',\n",
    "        'kansai_ben': 'Regional Dialect\\n(Kansai-ben)',\n",
    "        'direct_tone': 'Direct Expression\\nStyle'\n",
    "    }\n",
    "    \n",
    "    readable_names = [business_labels.get(name, name) for name in classic_names]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    colors = ['#2E86AB', '#A23B72', '#F18F01']\n",
    "    \n",
    "    bars = ax.barh(readable_names, classic_importance, color=colors, height=0.6)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for i, (bar, value) in enumerate(zip(bars, classic_importance)):\n",
    "        ax.text(value + max(classic_importance)*0.01, bar.get_y() + bar.get_height()/2, \n",
    "                f'{value:.3f}', ha='left', va='center', fontweight='bold', fontsize=11)\n",
    "    \n",
    "    ax.set_xlabel('Feature Importance Score', fontsize=12, fontweight='bold')\n",
    "    ax.set_title('Key Factors Influencing Sentiment Classification', \n",
    "                 fontsize=14, fontweight='bold', pad=20)\n",
    "    \n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.set_axisbelow(True)\n",
    "    ax.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return fig\n",
    "\n",
    "def create_executive_summary_table(classic_names, classic_importance):\n",
    "    \"\"\"Professional table with business insights\"\"\"\n",
    "    business_context = {\n",
    "        'length': {\n",
    "            'description': 'Length of customer feedback',\n",
    "            'insight': 'Longer texts tend to be more detailed complaints or praise',\n",
    "            'action': 'Monitor text length patterns for early sentiment detection'\n",
    "        },\n",
    "        'kansai_ben': {\n",
    "            'description': 'Regional dialect usage (Kansai area)',\n",
    "            'insight': 'Regional language patterns affect sentiment expression',\n",
    "            'action': 'Consider regional customization for better accuracy'\n",
    "        },\n",
    "        'direct_tone': {\n",
    "            'description': 'Direct/explicit expression style',\n",
    "            'insight': 'Direct language correlates with stronger sentiment',\n",
    "            'action': 'Prioritize direct feedback for immediate response'\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    summary_data = []\n",
    "    for name, importance in zip(classic_names, classic_importance):\n",
    "        context = business_context.get(name, {})\n",
    "        summary_data.append({\n",
    "            'Feature': context.get('description', name),\n",
    "            'Importance Score': f\"{importance:.3f}\",\n",
    "            'Business Insight': context.get('insight', 'N/A'),\n",
    "            'Recommended Action': context.get('action', 'N/A')\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(summary_data)\n",
    "\n",
    "def create_simple_comparison_chart(classic_names, classic_importance):\n",
    "    \"\"\"Very simple, clean comparison chart\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    \n",
    "    labels = ['Text Length', 'Regional Dialect', 'Direct Tone']\n",
    "    colors = plt.cm.viridis(np.linspace(0.3, 0.9, len(labels)))\n",
    "    \n",
    "    bars = ax.barh(labels, classic_importance, color=colors, height=0.5)\n",
    "    \n",
    "    # Add percentage labels\n",
    "    total_importance = sum(classic_importance)\n",
    "    for i, (bar, value) in enumerate(zip(bars, classic_importance)):\n",
    "        percentage = (value / total_importance) * 100\n",
    "        ax.text(value + max(classic_importance)*0.02, bar.get_y() + bar.get_height()/2, \n",
    "                f'{percentage:.1f}%', ha='left', va='center', fontweight='bold')\n",
    "    \n",
    "    ax.set_xlabel('Relative Importance', fontweight='bold')\n",
    "    ax.set_title('What Drives Sentiment Classification?', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.set_xlim(0, max(classic_importance) * 1.2)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return fig\n",
    "\n",
    "# Generate stakeholder-friendly visualizations\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"GENERATING STAKEHOLDER-FRIENDLY VISUALIZATIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. Business impact chart\n",
    "create_business_impact_chart(classic_names, classic_importance)\n",
    "\n",
    "# 2. Executive summary table\n",
    "df_executive_summary = create_executive_summary_table(classic_names, classic_importance)\n",
    "\n",
    "# 3. Simple comparison chart\n",
    "create_simple_comparison_chart(classic_names, classic_importance)\n",
    "\n",
    "# Print executive summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXECUTIVE SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(df_executive_summary.to_string(index=False))\n",
    "\n",
    "# Basic statistics for stakeholder report\n",
    "print(f\"\\nüìä MODEL PERFORMANCE SUMMARY:\")\n",
    "print(f\"   ‚Ä¢ Accuracy: {np.mean(df_test['sentiment'] == df_test['xgb_pred']):.1%}\")\n",
    "print(f\"   ‚Ä¢ Samples analyzed: {len(df_test)}\")\n",
    "print(f\"   ‚Ä¢ Regional dialect usage: {df_test['kansai_ben'].mean():.1%}\")\n",
    "print(f\"   ‚Ä¢ Direct expressions: {df_test['direct_tone'].mean():.1%}\")\n",
    "\n",
    "# Key takeaways for business\n",
    "print(f\"\\nüéØ KEY BUSINESS INSIGHTS:\")\n",
    "print(f\"   1. Text length is the strongest predictor of sentiment\")\n",
    "print(f\"   2. Regional dialect affects how sentiment is expressed\")\n",
    "print(f\"   3. Direct language correlates with stronger sentiment\")\n",
    "print(f\"   4. Model shows high accuracy for automated sentiment detection\")\n",
    "\n",
    "# ========================\n",
    "# 12. Display Results (Test)\n",
    "# ========================\n",
    "display_dataframe_to_user(name=\"JGLUE Sentiment + Kansai-ben Analysis (Test Set)\", dataframe=df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'on fleek' in translation_map? True\n",
      "Value for 'on fleek': something that is perfect or done really well\n",
      "Keys containing 'fleek': ['on fleek']\n",
      "\n",
      "--- Demo Replacement ---\n",
      "Original: I'm dead üòÇ, this party is on fleek!\n",
      "Mappings used in this sentence:\n",
      "  'on fleek' => 'something that is perfect or done really well'\n",
      "Translated: I'm dead üòÇ, this party is something that is perfect or done really well!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import io\n",
    "import re\n",
    "\n",
    "# 1. Load Gen-Z Slang CSV\n",
    "url_slang = \"https://raw.githubusercontent.com/kaspercools/genz-dataset/refs/heads/main/genz_slang.csv\"\n",
    "resp_slang = requests.get(url_slang)\n",
    "df_slang = pd.read_csv(io.StringIO(resp_slang.text))\n",
    "slang_map = {\n",
    "    str(row['keyword']).strip().lower(): str(row['description']).strip()\n",
    "    for _, row in df_slang.iterrows()\n",
    "    if pd.notnull(row['keyword']) and pd.notnull(row['description'])\n",
    "}\n",
    "\n",
    "# 2. Load Gen-Z Emojis CSV\n",
    "url_emoji = \"https://raw.githubusercontent.com/kaspercools/genz-dataset/refs/heads/main/genz_emojis.csv\"\n",
    "resp_emoji = requests.get(url_emoji)\n",
    "df_emoji = pd.read_csv(io.StringIO(resp_emoji.text))\n",
    "emoji_map = {\n",
    "    str(row['emoji']).strip(): str(row['Description']).strip()\n",
    "    for _, row in df_emoji.iterrows()\n",
    "    if pd.notnull(row['emoji']) and pd.notnull(row['Description'])\n",
    "}\n",
    "\n",
    "# 3. Phrase variants (auto-adds only if the base is present)\n",
    "variant_patterns = {\n",
    "    \"fleek\": [\"on fleek\"],\n",
    "    \"cap\": [\"no cap\"],\n",
    "    \"shade\": [\"throw shade\"],\n",
    "    \"tea\": [\"spill the tea\"],\n",
    "    \"key\": [\"low key\", \"high key\"],\n",
    "    \"bestie\": [\"bestie vibes\"],\n",
    "    \"grass\": [\"touch grass\"]\n",
    "}\n",
    "custom_phrase_map = {}\n",
    "for base, phrases in variant_patterns.items():\n",
    "    if base in slang_map:\n",
    "        for phrase in phrases:\n",
    "            custom_phrase_map[phrase] = slang_map[base]\n",
    "\n",
    "# 4. MANUAL BACKUPS for missing entries\n",
    "manual_phrase_map = {\n",
    "    \"on fleek\": \"something that is perfect or done really well\",\n",
    "    # Add more phrase backups here!\n",
    "}\n",
    "\n",
    "# 5. Merge all mappings, manual > custom > slang > emoji\n",
    "translation_map = {**manual_phrase_map, **custom_phrase_map, **slang_map, **emoji_map}\n",
    "\n",
    "print(\"'on fleek' in translation_map?\", \"on fleek\" in translation_map)\n",
    "print(\"Value for 'on fleek':\", translation_map.get(\"on fleek\"))\n",
    "print(\"Keys containing 'fleek':\", [k for k in translation_map if 'fleek' in k])\n",
    "\n",
    "def replace_slang_and_emoji(text, translation_map, verbose=False):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = str(text)\n",
    "    mapping_used = []\n",
    "    for key in sorted(translation_map.keys(), key=lambda x: -len(x)):\n",
    "        val = translation_map[key]\n",
    "        if re.match(r'^\\W+$', key):\n",
    "            if key in text and verbose:\n",
    "                mapping_used.append((key, val))\n",
    "            text = text.replace(key, val)\n",
    "        else:\n",
    "            pattern = r'(?i)(?<!\\w){}(?=\\W|$)'.format(re.escape(key))\n",
    "            if re.search(pattern, text):\n",
    "                if verbose:\n",
    "                    mapping_used.append((key, val))\n",
    "                text = re.sub(pattern, val, text)\n",
    "    if verbose:\n",
    "        print(\"Mappings used in this sentence:\")\n",
    "        if mapping_used:\n",
    "            for k, v in mapping_used:\n",
    "                print(f\"  '{k}' => '{v}'\")\n",
    "        else:\n",
    "            print(\"  (None)\")\n",
    "    return text\n",
    "\n",
    "demo_sentence = \"I'm dead üòÇ, this party is on fleek!\"\n",
    "print(\"\\n--- Demo Replacement ---\")\n",
    "print(\"Original:\", demo_sentence)\n",
    "translated = replace_slang_and_emoji(demo_sentence, translation_map, verbose=True)\n",
    "print(\"Translated:\", translated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to download livedoor-news-corpus...\n",
      "Trying URL 1: https://www.rondhuit.com/download/ldcc-20140209.tar.gz\n",
      "Downloading from URL 1...\n",
      "Progress: 356.6%\n",
      "Download complete. Verifying file...\n",
      "Invalid gzip signature: b'te'\n",
      "File verification failed. Trying next URL...\n",
      "Trying URL 2: http://www.rondhuit.com/download/ldcc-20140209.tar.gz\n",
      "Downloading from URL 2...\n",
      "Progress: 356.6%\n",
      "Download complete. Verifying file...\n",
      "Invalid gzip signature: b'te'\n",
      "File verification failed. Trying next URL...\n",
      "Failed to download the dataset. Using sample data instead.\n",
      "Creating sample data for demonstration...\n",
      "Created sample dataset: (1080, 2)\n",
      "\n",
      "Dataset label distribution:\n",
      "label\n",
      "dokujo-tsushin    120\n",
      "it-life-hack      120\n",
      "kaden-channel     120\n",
      "livedoor-homme    120\n",
      "movie-enter       120\n",
      "peachy            120\n",
      "smax              120\n",
      "sports-watch      120\n",
      "topic-news        120\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final dataset shape: (1080, 3)\n",
      "Label mapping: {'dokujo-tsushin': 0, 'it-life-hack': 1, 'kaden-channel': 2, 'livedoor-homme': 3, 'movie-enter': 4, 'peachy': 5, 'smax': 6, 'sports-watch': 7, 'topic-news': 8}\n",
      "\n",
      "First few samples:\n",
      "                              text           label  label_id\n",
      "0     ÂÅ•Â∫∑ÁöÑ„Å™ÁîüÊ¥ªÁøíÊÖ£„Å´„Å§„ÅÑ„Å¶ËÄÉ„Åà„Å¶„Åø„Åæ„Åó„Çá„ÅÜ„ÄÇ „Çµ„É≥„Éó„É´24  livedoor-homme         3\n",
      "1     ÊúâÂêç‰ø≥ÂÑ™„ÅÆÊúÄÊñ∞„Ç§„É≥„Çø„Éì„É•„Éº„Çí„ÅäÂ±ä„Åë„Åó„Åæ„Åô„ÄÇ „Çµ„É≥„Éó„É´29     movie-enter         4\n",
      "2  ÊúÄÊñ∞„Çπ„Éû„Éº„Éà„Éï„Ç©„É≥„ÅÆË©≥Á¥∞„É¨„Éì„É•„Éº„Çí„ÅäÂ±ä„Åë„Åó„Åæ„Åô„ÄÇ „Çµ„É≥„Éó„É´12            smax         6\n",
      "\n",
      "Processed data saved to 'livedoor_processed.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import os\n",
    "import tarfile\n",
    "import glob\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# ========================\n",
    "# 1. Download & Load livedoor-news-corpus with better error handling\n",
    "# ========================\n",
    "\n",
    "def download_livedoor_corpus():\n",
    "    \"\"\"Download livedoor corpus with multiple fallback strategies\"\"\"\n",
    "    \n",
    "    # Multiple possible URLs for the dataset\n",
    "    urls = [\n",
    "        \"https://www.rondhuit.com/download/ldcc-20140209.tar.gz\",\n",
    "        \"http://www.rondhuit.com/download/ldcc-20140209.tar.gz\",\n",
    "        # Alternative mirrors if needed\n",
    "    ]\n",
    "    \n",
    "    fname = \"ldcc-20140209.tar.gz\"\n",
    "    \n",
    "    # Remove existing file if it's corrupted\n",
    "    if os.path.exists(fname):\n",
    "        print(f\"Removing existing {fname} to retry download...\")\n",
    "        os.remove(fname)\n",
    "    \n",
    "    for i, url in enumerate(urls):\n",
    "        try:\n",
    "            print(f\"Trying URL {i+1}: {url}\")\n",
    "            \n",
    "            # Enhanced headers to mimic a real browser\n",
    "            headers = {\n",
    "                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
    "                'Accept-Language': 'en-US,en;q=0.5',\n",
    "                'Accept-Encoding': 'gzip, deflate',\n",
    "                'Connection': 'keep-alive',\n",
    "            }\n",
    "            \n",
    "            response = requests.get(url, headers=headers, timeout=30, stream=True)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            # Check if response is HTML (error page)\n",
    "            content_type = response.headers.get('content-type', '').lower()\n",
    "            if 'text/html' in content_type:\n",
    "                print(f\"URL {i+1} returned HTML instead of file\")\n",
    "                continue\n",
    "                \n",
    "            print(f\"Downloading from URL {i+1}...\")\n",
    "            total_size = int(response.headers.get('content-length', 0))\n",
    "            downloaded = 0\n",
    "            \n",
    "            with open(fname, \"wb\") as f:\n",
    "                for chunk in response.iter_content(chunk_size=8192):\n",
    "                    if chunk:\n",
    "                        f.write(chunk)\n",
    "                        downloaded += len(chunk)\n",
    "                        if total_size > 0:\n",
    "                            percent = (downloaded / total_size) * 100\n",
    "                            print(f\"\\rProgress: {percent:.1f}%\", end=\"\", flush=True)\n",
    "            \n",
    "            print(\"\\nDownload complete. Verifying file...\")\n",
    "            \n",
    "            # Verify the downloaded file\n",
    "            if verify_gzip_file(fname):\n",
    "                print(\"File verification successful!\")\n",
    "                return True\n",
    "            else:\n",
    "                print(\"File verification failed. Trying next URL...\")\n",
    "                os.remove(fname)\n",
    "                continue\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error with URL {i+1}: {e}\")\n",
    "            if os.path.exists(fname):\n",
    "                os.remove(fname)\n",
    "            continue\n",
    "    \n",
    "    return False\n",
    "\n",
    "def verify_gzip_file(fname):\n",
    "    \"\"\"Verify that the file is a valid gzip archive\"\"\"\n",
    "    try:\n",
    "        with open(fname, \"rb\") as f:\n",
    "            # Check gzip magic number\n",
    "            sig = f.read(2)\n",
    "            if sig != b'\\x1f\\x8b':\n",
    "                print(f\"Invalid gzip signature: {sig}\")\n",
    "                return False\n",
    "            \n",
    "            # Try to read the first few bytes to ensure it's not corrupted\n",
    "            f.seek(0)\n",
    "            with tarfile.open(fname, \"r\") as tar:\n",
    "                # Try to list contents\n",
    "                members = tar.getnames()[:5]  # Just check first 5 files\n",
    "                print(f\"Archive contains {len(tar.getnames())} files. Sample: {members}\")\n",
    "                return True\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"File verification error: {e}\")\n",
    "        return False\n",
    "\n",
    "def create_sample_data():\n",
    "    \"\"\"Create sample Japanese news data if download fails\"\"\"\n",
    "    print(\"Creating sample data for demonstration...\")\n",
    "    \n",
    "    # Sample Japanese news texts (simplified)\n",
    "    sample_data = {\n",
    "        'dokujo-tsushin': [\n",
    "            \"‰ªäÊó•„ÅØËâØ„ÅÑÂ§©Ê∞ó„Åß„Åó„Åü„ÄÇÂÖ¨Âúí„ÅßÊï£Ê≠©„ÇíÊ•Ω„Åó„Åø„Åæ„Åó„Åü„ÄÇ\",\n",
    "            \"Êñ∞„Åó„ÅÑ„Ç´„Éï„Çß„Åå„Ç™„Éº„Éó„É≥„Åó„Åæ„Åó„Åü„ÄÇ„Ç≥„Éº„Éí„Éº„Åå„Å®„Å¶„ÇÇÁæéÂë≥„Åó„ÅÑ„Åß„Åô„ÄÇ\",\n",
    "            \"ÂèãÈÅî„Å®Êò†Áîª„ÇíË¶ã„Å´Ë°å„Åç„Åæ„Åó„Åü„ÄÇ„Å®„Å¶„ÇÇÈù¢ÁôΩ„ÅÑÊò†Áîª„Åß„Åó„Åü„ÄÇ\"\n",
    "        ],\n",
    "        'it-life-hack': [\n",
    "            \"Êñ∞„Åó„ÅÑ„Éó„É≠„Ç∞„É©„Éü„É≥„Ç∞Ë®ÄË™û„ÇíÂ≠¶Áøí‰∏≠„Åß„Åô„ÄÇÈõ£„Åó„ÅÑ„Åß„Åô„ÅåÊ•Ω„Åó„ÅÑ„Åß„Åô„ÄÇ\",\n",
    "            \"ÊúÄÊñ∞„ÅÆ„Çπ„Éû„Éº„Éà„Éï„Ç©„É≥„ÅåÁô∫Â£≤„Åï„Çå„Åæ„Åó„Åü„ÄÇÊÄßËÉΩ„ÅåÂ§ßÂπÖ„Å´Âêë‰∏ä„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ\",\n",
    "            \"„ÇØ„É©„Ç¶„Éâ„Çµ„Éº„Éì„Çπ„ÅÆÊ¥ªÁî®ÊñπÊ≥ï„Å´„Å§„ÅÑ„Å¶Ë™¨Êòé„Åó„Åæ„Åô„ÄÇ\"\n",
    "        ],\n",
    "        'kaden-channel': [\n",
    "            \"ÊúÄÊñ∞„ÅÆÂÜ∑ËîµÂ∫´„ÅØÁúÅ„Ç®„ÉçÊ©üËÉΩ„ÅåÂÖÖÂÆü„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ\",\n",
    "            \"Êñ∞Âûã„Ç®„Ç¢„Ç≥„É≥„ÅÆÊÄßËÉΩÊØîËºÉ„ÇíË°å„ÅÑ„Åæ„Åó„Åü„ÄÇ\",\n",
    "            \"ÊéÉÈô§Ê©ü„ÅÆÈÅ∏„Å≥Êñπ„Å´„Å§„ÅÑ„Å¶Ë©≥„Åó„ÅèËß£Ë™¨„Åó„Åæ„Åô„ÄÇ\"\n",
    "        ],\n",
    "        'livedoor-homme': [\n",
    "            \"Áî∑ÊÄßÂêë„Åë„Éï„Ç°„ÉÉ„Ç∑„Éß„É≥„ÅÆÊúÄÊñ∞„Éà„É¨„É≥„Éâ„Çí„ÅîÁ¥π‰ªã„Åó„Åæ„Åô„ÄÇ\",\n",
    "            \"ÂÅ•Â∫∑ÁöÑ„Å™ÁîüÊ¥ªÁøíÊÖ£„Å´„Å§„ÅÑ„Å¶ËÄÉ„Åà„Å¶„Åø„Åæ„Åó„Çá„ÅÜ„ÄÇ\",\n",
    "            \"„Åä„Åô„Åô„ÇÅ„ÅÆ„Éò„Ç¢„Çπ„Çø„Ç§„É´„Çí„ÅîÊèêÊ°à„Åó„Åæ„Åô„ÄÇ\"\n",
    "        ],\n",
    "        'movie-enter': [\n",
    "            \"‰ªäÈÄ±ÂÖ¨Èñã„ÅÆÊò†Áîª„Çí„É¨„Éì„É•„Éº„Åó„Åæ„Åô„ÄÇ„Ç¢„ÇØ„Ç∑„Éß„É≥Êò†Áîª„ÅåÁâπ„Å´„Åä„Åô„Åô„ÇÅ„Åß„Åô„ÄÇ\",\n",
    "            \"ÊúâÂêç‰ø≥ÂÑ™„ÅÆÊúÄÊñ∞„Ç§„É≥„Çø„Éì„É•„Éº„Çí„ÅäÂ±ä„Åë„Åó„Åæ„Åô„ÄÇ\",\n",
    "            \"Êò†ÁîªÁ•≠„ÅÆÂèóË≥û‰ΩúÂìÅ„Å´„Å§„ÅÑ„Å¶Ë©≥„Åó„ÅèÁ¥π‰ªã„Åó„Åæ„Åô„ÄÇ\"\n",
    "        ],\n",
    "        'peachy': [\n",
    "            \"ÁæéÂÆπ„Å´Èñ¢„Åô„ÇãÊúÄÊñ∞ÊÉÖÂ†±„Çí„ÅäÂ±ä„Åë„Åó„Åæ„Åô„ÄÇ\",\n",
    "            \"„Çπ„Ç≠„É≥„Ç±„Ç¢„ÅÆÊ≠£„Åó„ÅÑÊñπÊ≥ï„Å´„Å§„ÅÑ„Å¶Ë™¨Êòé„Åó„Åæ„Åô„ÄÇ\",\n",
    "            \"Â≠£ÁØÄ„Å´Âêà„Çè„Åõ„Åü„É°„Ç§„ÇØ„Ç¢„ÉÉ„Éó„ÅÆ„Ç≥„ÉÑ„Çí„ÅîÁ¥π‰ªã„Åó„Åæ„Åô„ÄÇ\"\n",
    "        ],\n",
    "        'smax': [\n",
    "            \"ÊúÄÊñ∞„Çπ„Éû„Éº„Éà„Éï„Ç©„É≥„ÅÆË©≥Á¥∞„É¨„Éì„É•„Éº„Çí„ÅäÂ±ä„Åë„Åó„Åæ„Åô„ÄÇ\",\n",
    "            \"„É¢„Éê„Ç§„É´Ê•≠Áïå„ÅÆÊúÄÊñ∞ÂãïÂêë„Å´„Å§„ÅÑ„Å¶Ëß£Ë™¨„Åó„Åæ„Åô„ÄÇ\",\n",
    "            \"‰æøÂà©„Å™„Ç¢„Éó„É™„ÅÆ‰Ωø„ÅÑÊñπ„Çí„ÅîÁ¥π‰ªã„Åó„Åæ„Åô„ÄÇ\"\n",
    "        ],\n",
    "        'sports-watch': [\n",
    "            \"‰ªäÊó•„ÅÆÈáéÁêÉ„ÅÆË©¶ÂêàÁµêÊûú„Çí„Åä‰ºù„Åà„Åó„Åæ„Åô„ÄÇ\",\n",
    "            \"„Çµ„ÉÉ„Ç´„Éº„ÉØ„Éº„É´„Éâ„Ç´„ÉÉ„Éó„ÅÆÊúÄÊñ∞ÊÉÖÂ†±„Åß„Åô„ÄÇ\",\n",
    "            \"„Ç™„É™„É≥„Éî„ÉÉ„ÇØ„ÅÆÊ≥®ÁõÆÁ´∂ÊäÄ„Å´„Å§„ÅÑ„Å¶Ëß£Ë™¨„Åó„Åæ„Åô„ÄÇ\"\n",
    "        ],\n",
    "        'topic-news': [\n",
    "            \"ÊîøÊ≤ª„ÅÆÊúÄÊñ∞„Éã„É•„Éº„Çπ„Çí„ÅäÂ±ä„Åë„Åó„Åæ„Åô„ÄÇ\",\n",
    "            \"ÁµåÊ∏àÁä∂Ê≥Å„Å´„Å§„ÅÑ„Å¶Ë©≥„Åó„ÅèÂàÜÊûê„Åó„Åæ„Åô„ÄÇ\",\n",
    "            \"Á§æ‰ºöÂïèÈ°å„Å´„Å§„ÅÑ„Å¶ËÄÉÂØü„Åó„Åæ„Åô„ÄÇ\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    all_texts, all_labels = [], []\n",
    "    for label, texts in sample_data.items():\n",
    "        for text in texts:\n",
    "            # Duplicate each text multiple times to create more samples\n",
    "            for i in range(40):  # Create 40 samples per original text\n",
    "                all_texts.append(f\"{text} „Çµ„É≥„Éó„É´{i+1}\")\n",
    "                all_labels.append(label)\n",
    "    \n",
    "    return pd.DataFrame({\"text\": all_texts, \"label\": all_labels})\n",
    "\n",
    "# ========================\n",
    "# Main execution\n",
    "# ========================\n",
    "\n",
    "print(\"Attempting to download livedoor-news-corpus...\")\n",
    "\n",
    "# Try to download the real dataset\n",
    "if download_livedoor_corpus():\n",
    "    # Extract if not already done\n",
    "    if not os.path.exists(\"text\"):\n",
    "        print(\"Extracting...\")\n",
    "        with tarfile.open(\"ldcc-20140209.tar.gz\", \"r\") as tar:\n",
    "            tar.extractall()\n",
    "        print(\"Extraction complete.\")\n",
    "    else:\n",
    "        print(\"Directory 'text/' already exists.\")\n",
    "    \n",
    "    print(\"Sample of extracted category dirs:\", glob.glob(\"text/*\"))\n",
    "    \n",
    "    # Parse all files to DataFrame\n",
    "    all_texts, all_labels = [], []\n",
    "    for cat_folder in glob.glob(\"text/*\"):\n",
    "        cat = os.path.basename(cat_folder)\n",
    "        if not os.path.isdir(cat_folder):\n",
    "            continue\n",
    "        for file in glob.glob(f\"{cat_folder}/*.txt\"):\n",
    "            try:\n",
    "                with open(file, encoding=\"utf-8\") as f:\n",
    "                    lines = f.readlines()\n",
    "                    if len(lines) >= 3:  # [url, timestamp, title/body...]\n",
    "                        text = \"\".join(lines[2:]).strip()\n",
    "                        if text:  # Only add non-empty texts\n",
    "                            all_texts.append(text)\n",
    "                            all_labels.append(cat)\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading file {file}: {e}\")\n",
    "                continue\n",
    "    \n",
    "    df = pd.DataFrame({\"text\": all_texts, \"label\": all_labels})\n",
    "    print(\"Successfully loaded livedoor-news-corpus:\", df.shape)\n",
    "    \n",
    "else:\n",
    "    print(\"Failed to download the dataset. Using sample data instead.\")\n",
    "    df = create_sample_data()\n",
    "    print(\"Created sample dataset:\", df.shape)\n",
    "\n",
    "# Display dataset info\n",
    "print(\"\\nDataset label distribution:\")\n",
    "print(df['label'].value_counts().sort_index())\n",
    "\n",
    "# Sample and limit data for demo (remove these lines for full dataset)\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "df = df.groupby('label').head(120)  # Limit per class for memory/speed\n",
    "\n",
    "# Encode labels to integer\n",
    "le = LabelEncoder()\n",
    "df['label_id'] = le.fit_transform(df['label'])\n",
    "num_labels = df['label_id'].nunique()\n",
    "\n",
    "print(f\"\\nFinal dataset shape: {df.shape}\")\n",
    "print(\"Label mapping:\", dict(zip(le.classes_, range(num_labels))))\n",
    "print(\"\\nFirst few samples:\")\n",
    "print(df.head(3))\n",
    "\n",
    "# Save the processed data\n",
    "df.to_csv('livedoor_processed.csv', index=False)\n",
    "print(\"\\nProcessed data saved to 'livedoor_processed.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ÂÅ•Â∫∑ÁöÑ„Å™ÁîüÊ¥ªÁøíÊÖ£„Å´„Å§„ÅÑ„Å¶ËÄÉ„Åà„Å¶„Åø„Åæ„Åó„Çá„ÅÜ„ÄÇ „Çµ„É≥„Éó„É´24</td>\n",
       "      <td>livedoor-homme</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ÊúâÂêç‰ø≥ÂÑ™„ÅÆÊúÄÊñ∞„Ç§„É≥„Çø„Éì„É•„Éº„Çí„ÅäÂ±ä„Åë„Åó„Åæ„Åô„ÄÇ „Çµ„É≥„Éó„É´29</td>\n",
       "      <td>movie-enter</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ÊúÄÊñ∞„Çπ„Éû„Éº„Éà„Éï„Ç©„É≥„ÅÆË©≥Á¥∞„É¨„Éì„É•„Éº„Çí„ÅäÂ±ä„Åë„Åó„Åæ„Åô„ÄÇ „Çµ„É≥„Éó„É´12</td>\n",
       "      <td>smax</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Êò†ÁîªÁ•≠„ÅÆÂèóË≥û‰ΩúÂìÅ„Å´„Å§„ÅÑ„Å¶Ë©≥„Åó„ÅèÁ¥π‰ªã„Åó„Åæ„Åô„ÄÇ „Çµ„É≥„Éó„É´29</td>\n",
       "      <td>movie-enter</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Á§æ‰ºöÂïèÈ°å„Å´„Å§„ÅÑ„Å¶ËÄÉÂØü„Åó„Åæ„Åô„ÄÇ „Çµ„É≥„Éó„É´12</td>\n",
       "      <td>topic-news</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1075</th>\n",
       "      <td>ÊéÉÈô§Ê©ü„ÅÆÈÅ∏„Å≥Êñπ„Å´„Å§„ÅÑ„Å¶Ë©≥„Åó„ÅèËß£Ë™¨„Åó„Åæ„Åô„ÄÇ „Çµ„É≥„Éó„É´11</td>\n",
       "      <td>kaden-channel</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1076</th>\n",
       "      <td>„Åä„Åô„Åô„ÇÅ„ÅÆ„Éò„Ç¢„Çπ„Çø„Ç§„É´„Çí„ÅîÊèêÊ°à„Åó„Åæ„Åô„ÄÇ „Çµ„É≥„Éó„É´27</td>\n",
       "      <td>livedoor-homme</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1077</th>\n",
       "      <td>Êñ∞„Åó„ÅÑ„Éó„É≠„Ç∞„É©„Éü„É≥„Ç∞Ë®ÄË™û„ÇíÂ≠¶Áøí‰∏≠„Åß„Åô„ÄÇÈõ£„Åó„ÅÑ„Åß„Åô„ÅåÊ•Ω„Åó„ÅÑ„Åß„Åô„ÄÇ „Çµ„É≥„Éó„É´2</td>\n",
       "      <td>it-life-hack</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1078</th>\n",
       "      <td>Á§æ‰ºöÂïèÈ°å„Å´„Å§„ÅÑ„Å¶ËÄÉÂØü„Åó„Åæ„Åô„ÄÇ „Çµ„É≥„Éó„É´5</td>\n",
       "      <td>topic-news</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079</th>\n",
       "      <td>‰ªäÊó•„ÅÆÈáéÁêÉ„ÅÆË©¶ÂêàÁµêÊûú„Çí„Åä‰ºù„Åà„Åó„Åæ„Åô„ÄÇ „Çµ„É≥„Éó„É´21</td>\n",
       "      <td>sports-watch</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1080 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       text           label  label_id\n",
       "0              ÂÅ•Â∫∑ÁöÑ„Å™ÁîüÊ¥ªÁøíÊÖ£„Å´„Å§„ÅÑ„Å¶ËÄÉ„Åà„Å¶„Åø„Åæ„Åó„Çá„ÅÜ„ÄÇ „Çµ„É≥„Éó„É´24  livedoor-homme         3\n",
       "1              ÊúâÂêç‰ø≥ÂÑ™„ÅÆÊúÄÊñ∞„Ç§„É≥„Çø„Éì„É•„Éº„Çí„ÅäÂ±ä„Åë„Åó„Åæ„Åô„ÄÇ „Çµ„É≥„Éó„É´29     movie-enter         4\n",
       "2           ÊúÄÊñ∞„Çπ„Éû„Éº„Éà„Éï„Ç©„É≥„ÅÆË©≥Á¥∞„É¨„Éì„É•„Éº„Çí„ÅäÂ±ä„Åë„Åó„Åæ„Åô„ÄÇ „Çµ„É≥„Éó„É´12            smax         6\n",
       "3              Êò†ÁîªÁ•≠„ÅÆÂèóË≥û‰ΩúÂìÅ„Å´„Å§„ÅÑ„Å¶Ë©≥„Åó„ÅèÁ¥π‰ªã„Åó„Åæ„Åô„ÄÇ „Çµ„É≥„Éó„É´29     movie-enter         4\n",
       "4                     Á§æ‰ºöÂïèÈ°å„Å´„Å§„ÅÑ„Å¶ËÄÉÂØü„Åó„Åæ„Åô„ÄÇ „Çµ„É≥„Éó„É´12      topic-news         8\n",
       "...                                     ...             ...       ...\n",
       "1075            ÊéÉÈô§Ê©ü„ÅÆÈÅ∏„Å≥Êñπ„Å´„Å§„ÅÑ„Å¶Ë©≥„Åó„ÅèËß£Ë™¨„Åó„Åæ„Åô„ÄÇ „Çµ„É≥„Éó„É´11   kaden-channel         2\n",
       "1076             „Åä„Åô„Åô„ÇÅ„ÅÆ„Éò„Ç¢„Çπ„Çø„Ç§„É´„Çí„ÅîÊèêÊ°à„Åó„Åæ„Åô„ÄÇ „Çµ„É≥„Éó„É´27  livedoor-homme         3\n",
       "1077  Êñ∞„Åó„ÅÑ„Éó„É≠„Ç∞„É©„Éü„É≥„Ç∞Ë®ÄË™û„ÇíÂ≠¶Áøí‰∏≠„Åß„Åô„ÄÇÈõ£„Åó„ÅÑ„Åß„Åô„ÅåÊ•Ω„Åó„ÅÑ„Åß„Åô„ÄÇ „Çµ„É≥„Éó„É´2    it-life-hack         1\n",
       "1078                   Á§æ‰ºöÂïèÈ°å„Å´„Å§„ÅÑ„Å¶ËÄÉÂØü„Åó„Åæ„Åô„ÄÇ „Çµ„É≥„Éó„É´5      topic-news         8\n",
       "1079              ‰ªäÊó•„ÅÆÈáéÁêÉ„ÅÆË©¶ÂêàÁµêÊûú„Çí„Åä‰ºù„Åà„Åó„Åæ„Åô„ÄÇ „Çµ„É≥„Éó„É´21    sports-watch         7\n",
       "\n",
       "[1080 rows x 3 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading livedoor-news-corpus...\n",
      "File already exists: ldcc-20140209.tar.gz\n",
      "Directory 'text/' already exists.\n",
      "Sample of extracted category dirs: ['text/movie-enter', 'text/it-life-hack', 'text/kaden-channel', 'text/topic-news', 'text/livedoor-homme', 'text/peachy', 'text/sports-watch', 'text/dokujo-tsushin', 'text/CHANGES.txt', 'text/README.txt', 'text/smax']\n",
      "Loaded livedoor-news-corpus: (4976, 2)\n",
      "label\n",
      "kaden-channel     207\n",
      "livedoor-homme    512\n",
      "movie-enter       871\n",
      "peachy            843\n",
      "smax              871\n",
      "sports-watch      901\n",
      "topic-news        771\n",
      "Name: count, dtype: int64\n",
      "Label mapping: {'kaden-channel': 0, 'livedoor-homme': 1, 'movie-enter': 2, 'peachy': 3, 'smax': 4, 'sports-watch': 5, 'topic-news': 6}\n",
      "                                                text         label  label_id\n",
      "0  „ÄêSports Watch„Äë„Éï„Ç∏„ÉÜ„É¨„Éì„Éª„Çπ„Éù„Éº„ÉÑÁï™ÁµÑ„ÅÆ„ÄåÈüìÊó•Êà¶„ÄçË°®Ë®ò„ÅÆÁêÜÁî±„Å®„ÅØ\\nÂÖàÊúà‰∏ãÊó¨„ÄÅ...  sports-watch         5\n",
      "1  Â∑®Â§ßÈÉΩÂ∏Ç„Éã„É•„Éº„É®„Éº„ÇØÂêÑÊâÄ„Å´Âá∫Áèæ„Åó„Åü‚Äú„Å©„Åì„Åß„ÇÇ„Éâ„Ç¢‚Äù\\n„ÄÄËá™ÂÆÖ„ÇÑ„Ç™„Éï„Ç£„Çπ„Å™„Å©„ÄÅÊàë„ÄÖ„ÅØÊØéÊó•Êï∞„ÅàÂàá...   movie-enter         2\n",
      "2  5,000‰∏áÂÄãË≤©Â£≤„Åó„ÅüÂ§ß„Éí„ÉÉ„Éà„É≠„Éº„É´„Ç±„Éº„Ç≠„Å´„ÄåÁ¥ÖËå∂Âë≥„Äç„ÅåÊñ∞ÁôªÂ†¥\\n„ÄÄ„ÅÑ„Å§„Åß„ÇÇ„Åä„Ç¶„ÉÅ„Åå„Ç´„Éï„Çß„Å´...        peachy         3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import os\n",
    "import tarfile\n",
    "import glob\n",
    "\n",
    "# ========================\n",
    "# 1. Download & Load livedoor-news-corpus\n",
    "# ========================\n",
    "print(\"Downloading livedoor-news-corpus...\")\n",
    "url = \"https://www.rondhuit.com/download/ldcc-20140209.tar.gz\"\n",
    "fname = \"ldcc-20140209.tar.gz\"\n",
    "\n",
    "def download_if_needed(url, fname):\n",
    "    if not os.path.exists(fname):\n",
    "        print(\"Downloading...\")\n",
    "        headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "        with requests.get(url, stream=True, headers=headers) as r:\n",
    "            r.raise_for_status()\n",
    "            with open(fname, \"wb\") as f:\n",
    "                for chunk in r.iter_content(chunk_size=8192):\n",
    "                    f.write(chunk)\n",
    "        print(\"Download complete.\")\n",
    "    else:\n",
    "        print(\"File already exists:\", fname)\n",
    "    # Just check it's NOT html (error page)\n",
    "    with open(fname, \"rb\") as f:\n",
    "        head = f.read(512)\n",
    "        if b'<html' in head.lower() or b'<title' in head.lower():\n",
    "            raise RuntimeError(f\"{fname} looks like an HTML error page, not a tar file! Delete and retry.\")\n",
    "\n",
    "download_if_needed(url, fname)\n",
    "\n",
    "# Extract as **plain tar**, not gzip!\n",
    "if not os.path.exists(\"text\"):\n",
    "    print(\"Extracting...\")\n",
    "    try:\n",
    "        with tarfile.open(fname, \"r\") as tar:  # Note: \"r\", not \"r:gz\"\n",
    "            tar.extractall()\n",
    "        print(\"Extraction complete.\")\n",
    "    except Exception as e:\n",
    "        print(\"Extraction failed!\", e)\n",
    "else:\n",
    "    print(\"Directory 'text/' already exists.\")\n",
    "\n",
    "print(\"Sample of extracted category dirs:\", glob.glob(\"text/*\"))\n",
    "\n",
    "# ========================\n",
    "# 2. Parse All Files to DataFrame\n",
    "# ========================\n",
    "all_texts, all_labels = [], []\n",
    "for cat_folder in glob.glob(\"text/*\"):\n",
    "    cat = os.path.basename(cat_folder)\n",
    "    if not os.path.isdir(cat_folder):\n",
    "        continue\n",
    "    for file in glob.glob(f\"{cat_folder}/*.txt\"):\n",
    "        with open(file, encoding=\"utf-8\") as f:\n",
    "            lines = f.readlines()\n",
    "            if len(lines) >= 3:  # [url, timestamp, title/body...]\n",
    "                text = \"\".join(lines[2:]).strip()\n",
    "                all_texts.append(text)\n",
    "                all_labels.append(cat)\n",
    "\n",
    "df = pd.DataFrame({\"text\": all_texts, \"label\": all_labels})\n",
    "print(\"Loaded livedoor-news-corpus:\", df.shape)\n",
    "print(df['label'].value_counts().sort_index())\n",
    "\n",
    "# For demo: sample a small subset (for full training, remove .sample)\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "df = df.groupby('label').head(120)  # Limit per class for memory/speed\n",
    "\n",
    "# Encode labels to integer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df['label_id'] = le.fit_transform(df['label'])\n",
    "num_labels = df['label_id'].nunique()\n",
    "print(\"Label mapping:\", dict(zip(le.classes_, range(num_labels))))\n",
    "print(df.head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>UserID</th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Train/Dev/Test</th>\n",
       "      <th>Writer_Joy</th>\n",
       "      <th>Writer_Sadness</th>\n",
       "      <th>Writer_Anticipation</th>\n",
       "      <th>Writer_Surprise</th>\n",
       "      <th>Writer_Anger</th>\n",
       "      <th>Writer_Fear</th>\n",
       "      <th>...</th>\n",
       "      <th>Reader3_Disgust</th>\n",
       "      <th>Reader3_Trust</th>\n",
       "      <th>Avg. Readers_Joy</th>\n",
       "      <th>Avg. Readers_Sadness</th>\n",
       "      <th>Avg. Readers_Anticipation</th>\n",
       "      <th>Avg. Readers_Surprise</th>\n",
       "      <th>Avg. Readers_Anger</th>\n",
       "      <th>Avg. Readers_Fear</th>\n",
       "      <th>Avg. Readers_Disgust</th>\n",
       "      <th>Avg. Readers_Trust</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>„Åº„Åë„Å£„Å®„Åó„Å¶„Åü„Çâ„Åì„Çì„Å™ÊôÇÈñìÔΩ°„ÉÅ„É£„É™„ÅÇ„Çã„Åã„ÇâÈ£ü„Åπ„Å´„Åß„Åü„ÅÑ„ÅÆ„Å´‚Ä¶</td>\n",
       "      <td>1</td>\n",
       "      <td>2012/07/31 23:48</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>‰ªäÊó•„ÅÆÊúà„ÇÇÁôΩ„Åè„Å¶Êòé„Çã„ÅÑ„ÄÇÊò®Êó•„Çà„ÇäÈõ≤„ÅåÂ∞ë„Å™„Åè„Å¶„Ç≠„É¨„Ç§„Å™? „Å®Á´ã„Å°Ê≠¢„Åæ„ÇãÂ∏∞„ÇäÈÅìÔΩ°„ÉÅ„É£„É™„Å™„ÅóÁîüÊ¥ª„ÇÇ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2012/08/02 23:09</td>\n",
       "      <td>train</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Êó©ÂØù„Åô„Çã„Å§„ÇÇ„Çä„ÅåÈ£≤„ÅøÁâ©„Åå„Å™„Åè„Å™„Çä„Ç≥„É≥„Éì„Éã„Å∏ÔΩ°„ÇìÔΩ§‰ªäÊó•„ÄÅÈ¢®„ÅåÊ∂º„Åó„ÅÑ„Å™„ÄÇ</td>\n",
       "      <td>1</td>\n",
       "      <td>2012/08/05 00:50</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Áú†„ÅÑ„ÄÅÁú†„Çå„Å™„ÅÑ„ÄÇ</td>\n",
       "      <td>1</td>\n",
       "      <td>2012/08/08 01:36</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>„Åü„Å†„ÅÑ„Åæ? „Å£„Å¶Êñ∞‰ΩìÊìç„Åó„Å¶„Çã„ÇÑ„Çì!Â§ñÈ£ü„Åô„ÇãÊ∞óÊ∫Ä„ÄÖ„ÅßÂÆ∂„Å´‰Ωï„ÇÇ„Å™„ÅÑ„ÅÆ„Å´!„ÉÜ„É¨„Éì„Åã„ÇâÈõ¢„Çå„Çâ„Çå„Å™„ÅÑ‚Ä¶!</td>\n",
       "      <td>1</td>\n",
       "      <td>2012/08/09 22:24</td>\n",
       "      <td>train</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43195</th>\n",
       "      <td>ÁúüÂ§ú‰∏≠„Å´„Åµ„Å®ÊÄù„ÅÑÁ´ã„Å°„ÄÅ„Éé„Éº„ÉàPC„ÇíÊåÅ„Å£„Å¶ÈÉ®Â±ã„ÇíÂá∫„Å¶„ÄÅ„ÉÄ„Ç§„Éã„É≥„Ç∞„Åß‰ªï‰∫ã„Åó„Åü„Çâ„Åô„Çì„Åî„ÅÑÊçó„Å£„Åü„ÄÇ\\...</td>\n",
       "      <td>80</td>\n",
       "      <td>2020/09/15 08:01</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43196</th>\n",
       "      <td>„Åê„Å£„Å©„Åì„Çì„Åß„ÅÉ„Åó„Çá„Çì„ÄÇ\\nÂøÉ„ÇÇÈ†≠„ÇÇ„ÇØ„É™„Ç¢„ÄÇ\\nÁßãÂàÜ„ÅÆÊó•„ÅÆ„Åä„Åã„Åí„Åã„Å™Ôºü\\n‰∫∫„Å®Ëá™ÁÑ∂„Å®„Åó„Å£„Å®„ÇäÈÅé...</td>\n",
       "      <td>80</td>\n",
       "      <td>2020/09/22 01:52</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43197</th>\n",
       "      <td>Êúù„Åã„ÇâÂÖçË®±„ÅÆÊõ¥Êñ∞„Å∏„ÄÇ\\n90ÂàÜ„ÅßÁµÇ„Çè„Çä„ÄÅÂá∫Âè£„Å∏Âêë„Åã„ÅÜ„Å®ÁåÆË°Ä„ÅÆÂëº„Å≥„Åã„Åë„Åå„ÄÇ\\n„Åø„Çì„Å™ÈÄö„ÇäÈÅé„Åé„Å¶...</td>\n",
       "      <td>80</td>\n",
       "      <td>2020/09/23 22:32</td>\n",
       "      <td>train</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43198</th>\n",
       "      <td>Â§ú„ÇÇÊõ¥„Åë„Å¶ÂèÇ„Çä„Åæ„Åó„Åü„Åå„ÄÅÈ£üÂæå„ÅÆ„Ç≥„Éº„Éí„Éº„ÅåÈ£≤„Åø„Åü„ÅÑ„ÅÆ„Åß„Éâ„É™„ÉÉ„ÉóÈñãÂßã‚Ä¶\\n\\n„Åº„Çì„ÇÑ„ÇäÁßã„ÅÆÂ§úÈï∑„Çí...</td>\n",
       "      <td>80</td>\n",
       "      <td>2020/10/11 00:12</td>\n",
       "      <td>train</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43199</th>\n",
       "      <td>„Ç≥„Éº„Éí„Éº‰ºëÊÜ©ÔºàkahavitaukoÔºâ\\n\\n„ÅÑ„Å§„ÇÇ„ÅÆË±Ü„Å™„ÅÆ„Å´„Åô„Åî„ÅèÁæéÂë≥„Åó„Åè„Åß„Åç„Åü \\n\\n...</td>\n",
       "      <td>80</td>\n",
       "      <td>2020/10/16 12:55</td>\n",
       "      <td>train</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43200 rows √ó 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Sentence  UserID  \\\n",
       "0                         „Åº„Åë„Å£„Å®„Åó„Å¶„Åü„Çâ„Åì„Çì„Å™ÊôÇÈñìÔΩ°„ÉÅ„É£„É™„ÅÇ„Çã„Åã„ÇâÈ£ü„Åπ„Å´„Åß„Åü„ÅÑ„ÅÆ„Å´‚Ä¶       1   \n",
       "1      ‰ªäÊó•„ÅÆÊúà„ÇÇÁôΩ„Åè„Å¶Êòé„Çã„ÅÑ„ÄÇÊò®Êó•„Çà„ÇäÈõ≤„ÅåÂ∞ë„Å™„Åè„Å¶„Ç≠„É¨„Ç§„Å™? „Å®Á´ã„Å°Ê≠¢„Åæ„ÇãÂ∏∞„ÇäÈÅìÔΩ°„ÉÅ„É£„É™„Å™„ÅóÁîüÊ¥ª„ÇÇ...       1   \n",
       "2                     Êó©ÂØù„Åô„Çã„Å§„ÇÇ„Çä„ÅåÈ£≤„ÅøÁâ©„Åå„Å™„Åè„Å™„Çä„Ç≥„É≥„Éì„Éã„Å∏ÔΩ°„ÇìÔΩ§‰ªäÊó•„ÄÅÈ¢®„ÅåÊ∂º„Åó„ÅÑ„Å™„ÄÇ       1   \n",
       "3                                               Áú†„ÅÑ„ÄÅÁú†„Çå„Å™„ÅÑ„ÄÇ       1   \n",
       "4        „Åü„Å†„ÅÑ„Åæ? „Å£„Å¶Êñ∞‰ΩìÊìç„Åó„Å¶„Çã„ÇÑ„Çì!Â§ñÈ£ü„Åô„ÇãÊ∞óÊ∫Ä„ÄÖ„ÅßÂÆ∂„Å´‰Ωï„ÇÇ„Å™„ÅÑ„ÅÆ„Å´!„ÉÜ„É¨„Éì„Åã„ÇâÈõ¢„Çå„Çâ„Çå„Å™„ÅÑ‚Ä¶!       1   \n",
       "...                                                  ...     ...   \n",
       "43195  ÁúüÂ§ú‰∏≠„Å´„Åµ„Å®ÊÄù„ÅÑÁ´ã„Å°„ÄÅ„Éé„Éº„ÉàPC„ÇíÊåÅ„Å£„Å¶ÈÉ®Â±ã„ÇíÂá∫„Å¶„ÄÅ„ÉÄ„Ç§„Éã„É≥„Ç∞„Åß‰ªï‰∫ã„Åó„Åü„Çâ„Åô„Çì„Åî„ÅÑÊçó„Å£„Åü„ÄÇ\\...      80   \n",
       "43196  „Åê„Å£„Å©„Åì„Çì„Åß„ÅÉ„Åó„Çá„Çì„ÄÇ\\nÂøÉ„ÇÇÈ†≠„ÇÇ„ÇØ„É™„Ç¢„ÄÇ\\nÁßãÂàÜ„ÅÆÊó•„ÅÆ„Åä„Åã„Åí„Åã„Å™Ôºü\\n‰∫∫„Å®Ëá™ÁÑ∂„Å®„Åó„Å£„Å®„ÇäÈÅé...      80   \n",
       "43197  Êúù„Åã„ÇâÂÖçË®±„ÅÆÊõ¥Êñ∞„Å∏„ÄÇ\\n90ÂàÜ„ÅßÁµÇ„Çè„Çä„ÄÅÂá∫Âè£„Å∏Âêë„Åã„ÅÜ„Å®ÁåÆË°Ä„ÅÆÂëº„Å≥„Åã„Åë„Åå„ÄÇ\\n„Åø„Çì„Å™ÈÄö„ÇäÈÅé„Åé„Å¶...      80   \n",
       "43198  Â§ú„ÇÇÊõ¥„Åë„Å¶ÂèÇ„Çä„Åæ„Åó„Åü„Åå„ÄÅÈ£üÂæå„ÅÆ„Ç≥„Éº„Éí„Éº„ÅåÈ£≤„Åø„Åü„ÅÑ„ÅÆ„Åß„Éâ„É™„ÉÉ„ÉóÈñãÂßã‚Ä¶\\n\\n„Åº„Çì„ÇÑ„ÇäÁßã„ÅÆÂ§úÈï∑„Çí...      80   \n",
       "43199  „Ç≥„Éº„Éí„Éº‰ºëÊÜ©ÔºàkahavitaukoÔºâ\\n\\n„ÅÑ„Å§„ÇÇ„ÅÆË±Ü„Å™„ÅÆ„Å´„Åô„Åî„ÅèÁæéÂë≥„Åó„Åè„Åß„Åç„Åü \\n\\n...      80   \n",
       "\n",
       "               Datetime Train/Dev/Test  Writer_Joy  Writer_Sadness  \\\n",
       "0      2012/07/31 23:48          train           0               1   \n",
       "1      2012/08/02 23:09          train           3               0   \n",
       "2      2012/08/05 00:50          train           1               1   \n",
       "3      2012/08/08 01:36          train           0               2   \n",
       "4      2012/08/09 22:24          train           2               1   \n",
       "...                 ...            ...         ...             ...   \n",
       "43195  2020/09/15 08:01          train           0               0   \n",
       "43196  2020/09/22 01:52          train           1               0   \n",
       "43197  2020/09/23 22:32          train           2               0   \n",
       "43198  2020/10/11 00:12          train           2               0   \n",
       "43199  2020/10/16 12:55          train           2               0   \n",
       "\n",
       "       Writer_Anticipation  Writer_Surprise  Writer_Anger  Writer_Fear  ...  \\\n",
       "0                        2                1             1            0  ...   \n",
       "1                        3                0             0            0  ...   \n",
       "2                        1                1             0            0  ...   \n",
       "3                        1                0             0            1  ...   \n",
       "4                        3                2             0            1  ...   \n",
       "...                    ...              ...           ...          ...  ...   \n",
       "43195                    1                0             0            0  ...   \n",
       "43196                    1                0             0            0  ...   \n",
       "43197                    2                1             0            0  ...   \n",
       "43198                    1                0             0            0  ...   \n",
       "43199                    1                0             0            0  ...   \n",
       "\n",
       "       Reader3_Disgust  Reader3_Trust  Avg. Readers_Joy  Avg. Readers_Sadness  \\\n",
       "0                    1              0                 0                     2   \n",
       "1                    0              1                 1                     0   \n",
       "2                    0              0                 0                     0   \n",
       "3                    2              0                 0                     1   \n",
       "4                    0              0                 1                     0   \n",
       "...                ...            ...               ...                   ...   \n",
       "43195                0              0                 1                     0   \n",
       "43196                0              0                 2                     0   \n",
       "43197                0              0                 2                     0   \n",
       "43198                0              0                 0                     0   \n",
       "43199                0              2                 2                     0   \n",
       "\n",
       "       Avg. Readers_Anticipation  Avg. Readers_Surprise  Avg. Readers_Anger  \\\n",
       "0                              0                      0                   0   \n",
       "1                              0                      2                   0   \n",
       "2                              0                      1                   0   \n",
       "3                              0                      0                   0   \n",
       "4                              0                      1                   0   \n",
       "...                          ...                    ...                 ...   \n",
       "43195                          0                      1                   0   \n",
       "43196                          2                      0                   0   \n",
       "43197                          0                      0                   0   \n",
       "43198                          2                      0                   0   \n",
       "43199                          0                      0                   0   \n",
       "\n",
       "       Avg. Readers_Fear  Avg. Readers_Disgust  Avg. Readers_Trust  \n",
       "0                      0                     0                   0  \n",
       "1                      0                     0                   0  \n",
       "2                      0                     0                   0  \n",
       "3                      0                     1                   0  \n",
       "4                      0                     0                   0  \n",
       "...                  ...                   ...                 ...  \n",
       "43195                  0                     0                   0  \n",
       "43196                  0                     0                   0  \n",
       "43197                  0                     0                   0  \n",
       "43198                  0                     0                   0  \n",
       "43199                  0                     0                   1  \n",
       "\n",
       "[43200 rows x 44 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "wrime_url = \"https://raw.githubusercontent.com/ids-cv/wrime/refs/heads/master/wrime-ver1.tsv\"\n",
    "wrime_path = \"wrime-ver1.tsv\"\n",
    "if not os.path.exists(wrime_path):\n",
    "    r = requests.get(wrime_url)\n",
    "    open(wrime_path, \"wb\").write(r.content)\n",
    "df_wrime = pd.read_csv(wrime_path, sep=\"\\t\")\n",
    "df_wrime = df_wrime.dropna(subset=[\"Sentence\"])\n",
    "df_wrime"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "https://storage.googleapis.com/kaggle-colab-exported-notebooks/misfits/notebookd4cfb385ee.b94b9b4d-feb6-476f-836e-b6a74e98ef5c.ipynb?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com/20250612/auto/storage/goog4_request&X-Goog-Date=20250612T131831Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=aeb880bf0c73e8f64c855b028a441c37077c446901b1d4906c1e568dbdb91ef896647d9587b0fc3d22628372a981ab8f7a9166cc13a3ac869d9b5609862fcf22e843f6675a66c500826d8f77c428721ccfcb8d2301dbeff8f5ee129021ec173dd252b30806d1faff927d87dfacba0558e3b287e8ae442ad1556aaa15cf6e692320ca96522b846b4e6ea20866c5bce56c44c2e5ddd6acbc82274a98ac4cf844ba57f0184b33f952f3cac4157a2e43e0f93600bd0207edbcd74b3224c6021d6b9fe8f4562ef63d8d45c9c3c2f86f4314907ac22553f0c647a51ab276959a5a959cf2753d23909bd1e29b935ee3fd1bde19f0ebed4dbcdb4f1336441bfa2e03e260",
     "timestamp": 1749748853251
    }
   ]
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0913fa97ccd74ef49a00ee04b63ea6bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8b53bd89d0b34ddaae3115a653e0d775",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_59aa76f235764770b2382ee79efeb575",
      "value": "tokenizer_config.json:‚Äá100%"
     }
    },
    "12ec674eff1d4989955fcbed87554ffd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "18cd81a4ce594285ab1081fa723f005a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aa8acb1f146642ca9446be325ffc9e31",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_708c6c94c066489081ad8875d00e3b51",
      "value": "‚Äá236k/236k‚Äá[00:00&lt;00:00,‚Äá3.84MB/s]"
     }
    },
    "19aa71867f6f42a88e6bbe811b354e30": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "25233e339a77418a846f7ed7dbc906c0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "27fca39b431c48c394fdb434760570d0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_94103ec6f7364f54a10460fcaa83713c",
      "max": 236001,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_19aa71867f6f42a88e6bbe811b354e30",
      "value": 236001
     }
    },
    "44a143b60fd1446cb35dbe21d5de0bf4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "47fa45983dca46de914fb882917a8422": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_da2bdb8ad23c4ecbb0f3dadc569a5b55",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_81169d8b554a4e9aa65eed52538bb0f0",
      "value": "config.json:‚Äá100%"
     }
    },
    "557028e8e3a7418d913b0eafc59a4e99": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "55f3c34729de4f01a1b8245ee5723220": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "59aa76f235764770b2382ee79efeb575": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "602c48c5116141109cbd7bdd4b76544a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a4a95fd3ca1a48bd8a7886f46b7d2410",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_a4df42534a4f42f4adb067d25838788a",
      "value": "‚Äá174/174‚Äá[00:00&lt;00:00,‚Äá5.67kB/s]"
     }
    },
    "6b729dbc1b204303b12d44def92e5af9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0913fa97ccd74ef49a00ee04b63ea6bf",
       "IPY_MODEL_9598dbe3b1c64dadad37002cd73a81cf",
       "IPY_MODEL_602c48c5116141109cbd7bdd4b76544a"
      ],
      "layout": "IPY_MODEL_ec7ec7303f8c4284871fd36e628db99f"
     }
    },
    "708c6c94c066489081ad8875d00e3b51": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "762858486a7b4858b9bdc025219a169f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "81169d8b554a4e9aa65eed52538bb0f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8b53bd89d0b34ddaae3115a653e0d775": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8e673ea2d9e44aad83d83fdee8e1eed6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_af0c0d8edbec4611bf611d2ac4b85c1c",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_d4de67040a2942ebad27e94be89778b2",
      "value": "vocab.txt:‚Äá100%"
     }
    },
    "94103ec6f7364f54a10460fcaa83713c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9598dbe3b1c64dadad37002cd73a81cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bdd7f2df67c54ba3a31c859984b9a8ac",
      "max": 174,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_557028e8e3a7418d913b0eafc59a4e99",
      "value": 174
     }
    },
    "a2fa6d052cc54e94a8a4d8be7d18b3ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8e673ea2d9e44aad83d83fdee8e1eed6",
       "IPY_MODEL_27fca39b431c48c394fdb434760570d0",
       "IPY_MODEL_18cd81a4ce594285ab1081fa723f005a"
      ],
      "layout": "IPY_MODEL_55f3c34729de4f01a1b8245ee5723220"
     }
    },
    "a4a95fd3ca1a48bd8a7886f46b7d2410": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a4df42534a4f42f4adb067d25838788a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "aa8acb1f146642ca9446be325ffc9e31": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "af0c0d8edbec4611bf611d2ac4b85c1c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bdd7f2df67c54ba3a31c859984b9a8ac": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d4de67040a2942ebad27e94be89778b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "da2bdb8ad23c4ecbb0f3dadc569a5b55": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ebdcfad4799d498b99a4ebfe98819aa3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_25233e339a77418a846f7ed7dbc906c0",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_12ec674eff1d4989955fcbed87554ffd",
      "value": "‚Äá517/517‚Äá[00:00&lt;00:00,‚Äá22.1kB/s]"
     }
    },
    "ec7ec7303f8c4284871fd36e628db99f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ef404e26e95f4fc6b5d3e46e07daab96": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_44a143b60fd1446cb35dbe21d5de0bf4",
      "max": 517,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ffb4d6bc88bf4b14a325ff9a2fc154e0",
      "value": 517
     }
    },
    "ef972f5ca5d3454b857849a9fa1df2a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_47fa45983dca46de914fb882917a8422",
       "IPY_MODEL_ef404e26e95f4fc6b5d3e46e07daab96",
       "IPY_MODEL_ebdcfad4799d498b99a4ebfe98819aa3"
      ],
      "layout": "IPY_MODEL_762858486a7b4858b9bdc025219a169f"
     }
    },
    "ffb4d6bc88bf4b14a325ff9a2fc154e0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
