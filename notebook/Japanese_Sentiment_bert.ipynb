{"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"colab":{"provenance":[{"file_id":"https://storage.googleapis.com/kaggle-colab-exported-notebooks/misfits/notebookd4cfb385ee.b94b9b4d-feb6-476f-836e-b6a74e98ef5c.ipynb?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com/20250612/auto/storage/goog4_request&X-Goog-Date=20250612T131831Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=aeb880bf0c73e8f64c855b028a441c37077c446901b1d4906c1e568dbdb91ef896647d9587b0fc3d22628372a981ab8f7a9166cc13a3ac869d9b5609862fcf22e843f6675a66c500826d8f77c428721ccfcb8d2301dbeff8f5ee129021ec173dd252b30806d1faff927d87dfacba0558e3b287e8ae442ad1556aaa15cf6e692320ca96522b846b4e6ea20866c5bce56c44c2e5ddd6acbc82274a98ac4cf844ba57f0184b33f952f3cac4157a2e43e0f93600bd0207edbcd74b3224c6021d6b9fe8f4562ef63d8d45c9c3c2f86f4314907ac22553f0c647a51ab276959a5a959cf2753d23909bd1e29b935ee3fd1bde19f0ebed4dbcdb4f1336441bfa2e03e260","timestamp":1749748853251}]},"widgets":{"application/vnd.jupyter.widget-state+json":{"6b729dbc1b204303b12d44def92e5af9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0913fa97ccd74ef49a00ee04b63ea6bf","IPY_MODEL_9598dbe3b1c64dadad37002cd73a81cf","IPY_MODEL_602c48c5116141109cbd7bdd4b76544a"],"layout":"IPY_MODEL_ec7ec7303f8c4284871fd36e628db99f"}},"0913fa97ccd74ef49a00ee04b63ea6bf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8b53bd89d0b34ddaae3115a653e0d775","placeholder":"​","style":"IPY_MODEL_59aa76f235764770b2382ee79efeb575","value":"tokenizer_config.json: 100%"}},"9598dbe3b1c64dadad37002cd73a81cf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bdd7f2df67c54ba3a31c859984b9a8ac","max":174,"min":0,"orientation":"horizontal","style":"IPY_MODEL_557028e8e3a7418d913b0eafc59a4e99","value":174}},"602c48c5116141109cbd7bdd4b76544a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a4a95fd3ca1a48bd8a7886f46b7d2410","placeholder":"​","style":"IPY_MODEL_a4df42534a4f42f4adb067d25838788a","value":" 174/174 [00:00&lt;00:00, 5.67kB/s]"}},"ec7ec7303f8c4284871fd36e628db99f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8b53bd89d0b34ddaae3115a653e0d775":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"59aa76f235764770b2382ee79efeb575":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bdd7f2df67c54ba3a31c859984b9a8ac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"557028e8e3a7418d913b0eafc59a4e99":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a4a95fd3ca1a48bd8a7886f46b7d2410":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a4df42534a4f42f4adb067d25838788a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ef972f5ca5d3454b857849a9fa1df2a6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_47fa45983dca46de914fb882917a8422","IPY_MODEL_ef404e26e95f4fc6b5d3e46e07daab96","IPY_MODEL_ebdcfad4799d498b99a4ebfe98819aa3"],"layout":"IPY_MODEL_762858486a7b4858b9bdc025219a169f"}},"47fa45983dca46de914fb882917a8422":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_da2bdb8ad23c4ecbb0f3dadc569a5b55","placeholder":"​","style":"IPY_MODEL_81169d8b554a4e9aa65eed52538bb0f0","value":"config.json: 100%"}},"ef404e26e95f4fc6b5d3e46e07daab96":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_44a143b60fd1446cb35dbe21d5de0bf4","max":517,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ffb4d6bc88bf4b14a325ff9a2fc154e0","value":517}},"ebdcfad4799d498b99a4ebfe98819aa3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_25233e339a77418a846f7ed7dbc906c0","placeholder":"​","style":"IPY_MODEL_12ec674eff1d4989955fcbed87554ffd","value":" 517/517 [00:00&lt;00:00, 22.1kB/s]"}},"762858486a7b4858b9bdc025219a169f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"da2bdb8ad23c4ecbb0f3dadc569a5b55":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"81169d8b554a4e9aa65eed52538bb0f0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"44a143b60fd1446cb35dbe21d5de0bf4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ffb4d6bc88bf4b14a325ff9a2fc154e0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"25233e339a77418a846f7ed7dbc906c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"12ec674eff1d4989955fcbed87554ffd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a2fa6d052cc54e94a8a4d8be7d18b3ee":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8e673ea2d9e44aad83d83fdee8e1eed6","IPY_MODEL_27fca39b431c48c394fdb434760570d0","IPY_MODEL_18cd81a4ce594285ab1081fa723f005a"],"layout":"IPY_MODEL_55f3c34729de4f01a1b8245ee5723220"}},"8e673ea2d9e44aad83d83fdee8e1eed6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_af0c0d8edbec4611bf611d2ac4b85c1c","placeholder":"​","style":"IPY_MODEL_d4de67040a2942ebad27e94be89778b2","value":"vocab.txt: 100%"}},"27fca39b431c48c394fdb434760570d0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_94103ec6f7364f54a10460fcaa83713c","max":236001,"min":0,"orientation":"horizontal","style":"IPY_MODEL_19aa71867f6f42a88e6bbe811b354e30","value":236001}},"18cd81a4ce594285ab1081fa723f005a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_aa8acb1f146642ca9446be325ffc9e31","placeholder":"​","style":"IPY_MODEL_708c6c94c066489081ad8875d00e3b51","value":" 236k/236k [00:00&lt;00:00, 3.84MB/s]"}},"55f3c34729de4f01a1b8245ee5723220":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af0c0d8edbec4611bf611d2ac4b85c1c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d4de67040a2942ebad27e94be89778b2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"94103ec6f7364f54a10460fcaa83713c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"19aa71867f6f42a88e6bbe811b354e30":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"aa8acb1f146642ca9446be325ffc9e31":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"708c6c94c066489081ad8875d00e3b51":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"code","source":["import torch\n","print(\"CUDA available:\", torch.cuda.is_available())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dfTjYNifrfFP","executionInfo":{"status":"ok","timestamp":1749745839913,"user_tz":-120,"elapsed":11956,"user":{"displayName":"","userId":""}},"outputId":"e7cb8ee5-9510-42b7-800f-2808e2fd5f23"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["CUDA available: False\n"]}]},{"cell_type":"code","source":["import transformers\n","print(transformers.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7Nr0KW0ZiCea","executionInfo":{"status":"ok","timestamp":1749745845854,"user_tz":-120,"elapsed":5942,"user":{"displayName":"","userId":""}},"outputId":"59410d81-c86a-4a5b-d5a3-a9f0d0cc9a7a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["4.52.4\n"]}]},{"cell_type":"code","source":["!pip install certifi\n","!mkdir -p /usr/local/share/ca-certificates/\n","!cp /etc/ssl/certs/ca-certificates.crt /usr/local/share/ca-certificates/\n","!update-ca-certificates\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7TK8QWC8kvZa","executionInfo":{"status":"ok","timestamp":1749745864901,"user_tz":-120,"elapsed":19046,"user":{"displayName":"","userId":""}},"outputId":"ae8ac29b-aad2-4f64-d6cb-e0d0056a38c5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (2025.4.26)\n","Updating certificates in /etc/ssl/certs...\n","rehash: warning: skipping ca-certificates.crt,it does not contain exactly one certificate or CRL\n","rehash: warning: skipping ca-certificates.pem,it does not contain exactly one certificate or CRL\n","1 added, 0 removed; done.\n","Running hooks in /etc/ca-certificates/update.d...\n","\n","Adding debian:ca-certificates.pem\n","done.\n","done.\n"]}]},{"cell_type":"code","source":["# ========================\n","# 1. Imports & Setup\n","# ========================\n","from tqdm import tqdm\n","import torch\n","import pandas as pd\n","import numpy as np\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","from peft import get_peft_model, LoraConfig, TaskType\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Using device:\", device)\n","\n","# ========================\n","# 2. Kansai-ben & Directness Detection\n","# ========================\n","kansaiben_keywords = [\"〜やん\", \"〜やで\", \"〜せなあかん\", \"ちゃう\", \"ほんま\", \"めっちゃ\", \"〜せんと\", \"なんでやねん\"]\n","def detect_kansaiben(text):\n","    return any(k in text for k in kansaiben_keywords)\n","\n","# Heuristic for \"direct tone\" detection\n","def detect_directness(text):\n","    # Phrases common in direct or strong opinions\n","    direct_phrases = [\"最悪\", \"ありえない\", \"めっちゃ\", \"だめ\", \"良い\", \"良くない\", \"おすすめ\", \"絶対\", \"微妙\"]\n","    return any(word in text for word in direct_phrases)\n","\n","# ========================\n","# 3. Load JGLUE Dataset\n","# ========================\n","def load_jsts_json(url):\n","    df = pd.read_json(url, lines=True)\n","    df['text'] = df['sentence1'] + \" \" + df['sentence2']\n","    df['sentiment'] = df['label'].apply(lambda x: 0 if x < 2 else (1 if x <= 3 else 2))\n","    return df[['text', 'sentiment']]\n","\n","df_train = load_jsts_json(\"https://raw.githubusercontent.com/yahoojapan/JGLUE/refs/heads/main/datasets/jsts-v1.3/train-v1.3.json\").sample(500, random_state=42)\n","df_valid = load_jsts_json(\"https://raw.githubusercontent.com/yahoojapan/JGLUE/refs/heads/main/datasets/jsts-v1.3/valid-v1.3.json\").sample(100, random_state=42)\n","\n","# ========================\n","# 4. Tokenization & Dataset\n","# ========================\n","model_name = \"cl-tohoku/bert-base-japanese-v2\"\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","\n","def tokenize_batch(texts):\n","    return tokenizer(list(texts), truncation=True, padding=\"max_length\", max_length=128, return_tensors='pt')\n","\n","class SimpleDataset(torch.utils.data.Dataset):\n","    def __init__(self, df):\n","        self.encodings = tokenize_batch(df['text'])\n","        self.labels = torch.tensor(df['sentiment'].values)\n","    def __getitem__(self, idx):\n","        item = {k: v[idx] for k, v in self.encodings.items()}\n","        item[\"labels\"] = self.labels[idx]\n","        return item\n","    def __len__(self):\n","        return len(self.labels)\n","\n","train_ds = SimpleDataset(df_train)\n","eval_ds = SimpleDataset(df_valid)\n","\n","# ========================\n","# 5. LoRA Model Init\n","# ========================\n","base_model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)\n","peft_config = LoraConfig(task_type=TaskType.SEQ_CLS, r=8, lora_alpha=16, lora_dropout=0.1, bias=\"none\")\n","model = get_peft_model(base_model, peft_config).to(device)\n","\n","# ========================\n","# 6. Custom Training Loop with tqdm\n","# ========================\n","from torch.utils.data import DataLoader\n","from torch.optim import AdamW\n","\n","train_loader = DataLoader(train_ds, batch_size=8, shuffle=True)\n","optimizer = AdamW(model.parameters(), lr=2e-5)\n","loss_fn = torch.nn.CrossEntropyLoss()\n","\n","model.train()\n","loss_history = []\n","\n","for epoch in range(1):  # 1 epoch\n","    loop = tqdm(train_loader, desc=\"Training\")\n","    for batch in loop:\n","        input_ids = batch['input_ids'].to(device)\n","        attention_mask = batch['attention_mask'].to(device)\n","        labels = batch['labels'].to(device)\n","\n","        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n","        loss = outputs.loss\n","        loss.backward()\n","        optimizer.step()\n","        optimizer.zero_grad()\n","\n","        loss_history.append(loss.item())\n","        loop.set_postfix(loss=loss.item())\n","\n","# ========================\n","# 7. Inference Function\n","# ========================\n","def predict_sentiment(text):\n","    inputs = tokenizer(str(text), return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=128).to(device)\n","    model.eval()\n","    with torch.no_grad():\n","        outputs = model(**inputs)\n","        probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n","    labels = [\"Negative\", \"Neutral\", \"Positive\"]\n","    return labels[probs.argmax().item()]\n","\n","# ========================\n","# 8. Merge & Analyze\n","# ========================\n","df_amz = pd.DataFrame({'content': df_train['text'][:30]})\n","df_amz['source'] = 'JGLUE'\n","df_amz['predicted_sentiment'] = df_amz['content'].apply(predict_sentiment)\n","df_amz['kansai_ben'] = df_amz['content'].apply(detect_kansaiben)\n","df_amz['direct_tone'] = df_amz['content'].apply(detect_directness)\n","\n","# Add mock external sources\n","df_x = pd.DataFrame({'content': [\"これは良い商品やで\", \"最悪やんけ！\"], 'source': ['X', 'X']})\n","df_fb = pd.DataFrame({'content': [\"本当に素晴らしい\", \"ちょっとちゃうねん\"], 'source': ['Facebook', 'Facebook']})\n","for df in [df_x, df_fb]:\n","    df['predicted_sentiment'] = df['content'].apply(predict_sentiment)\n","    df['kansai_ben'] = df['content'].apply(detect_kansaiben)\n","    df['direct_tone'] = df['content'].apply(detect_directness)\n","\n","df_all = pd.concat([df_amz, df_x, df_fb], ignore_index=True)\n","print(\"\\nSample Results:\\n\", df_all.head(10))\n","\n","# ========================\n","# 9. Visualization\n","# ========================\n","plt.figure(figsize=(8, 4))\n","sns.countplot(data=df_all, x='predicted_sentiment', hue='source')\n","plt.title(\"Sentiment Distribution by Source\")\n","plt.tight_layout()\n","plt.show()\n","\n","plt.figure(figsize=(7, 3))\n","sns.countplot(data=df_all, x='direct_tone', hue='source')\n","plt.title(\"Direct Tone Presence by Source\")\n","plt.tight_layout()\n","plt.show()\n","\n","plt.figure(figsize=(7, 3))\n","sns.countplot(data=df_all, x='kansai_ben', hue='source')\n","plt.title(\"Kansai-ben Detection by Source\")\n","plt.tight_layout()\n","plt.show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":926,"referenced_widgets":["6b729dbc1b204303b12d44def92e5af9","0913fa97ccd74ef49a00ee04b63ea6bf","9598dbe3b1c64dadad37002cd73a81cf","602c48c5116141109cbd7bdd4b76544a","ec7ec7303f8c4284871fd36e628db99f","8b53bd89d0b34ddaae3115a653e0d775","59aa76f235764770b2382ee79efeb575","bdd7f2df67c54ba3a31c859984b9a8ac","557028e8e3a7418d913b0eafc59a4e99","a4a95fd3ca1a48bd8a7886f46b7d2410","a4df42534a4f42f4adb067d25838788a","ef972f5ca5d3454b857849a9fa1df2a6","47fa45983dca46de914fb882917a8422","ef404e26e95f4fc6b5d3e46e07daab96","ebdcfad4799d498b99a4ebfe98819aa3","762858486a7b4858b9bdc025219a169f","da2bdb8ad23c4ecbb0f3dadc569a5b55","81169d8b554a4e9aa65eed52538bb0f0","44a143b60fd1446cb35dbe21d5de0bf4","ffb4d6bc88bf4b14a325ff9a2fc154e0","25233e339a77418a846f7ed7dbc906c0","12ec674eff1d4989955fcbed87554ffd","a2fa6d052cc54e94a8a4d8be7d18b3ee","8e673ea2d9e44aad83d83fdee8e1eed6","27fca39b431c48c394fdb434760570d0","18cd81a4ce594285ab1081fa723f005a","55f3c34729de4f01a1b8245ee5723220","af0c0d8edbec4611bf611d2ac4b85c1c","d4de67040a2942ebad27e94be89778b2","94103ec6f7364f54a10460fcaa83713c","19aa71867f6f42a88e6bbe811b354e30","aa8acb1f146642ca9446be325ffc9e31","708c6c94c066489081ad8875d00e3b51"]},"id":"mMxTA1g2UHy6","executionInfo":{"status":"error","timestamp":1749745898528,"user_tz":-120,"elapsed":33625,"user":{"displayName":"","userId":""}},"outputId":"d8bd9a0f-ec7a-4ee6-80f3-0980744bcdc9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cpu\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/174 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b729dbc1b204303b12d44def92e5af9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/517 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef972f5ca5d3454b857849a9fa1df2a6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/236k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a2fa6d052cc54e94a8a4d8be7d18b3ee"}},"metadata":{}},{"output_type":"error","ename":"ModuleNotFoundError","evalue":"You need to install fugashi to use MecabTokenizer. See https://pypi.org/project/fugashi/ for installation.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert_japanese/tokenization_bert_japanese.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, do_lower_case, never_split, normalize_text, mecab_dic, mecab_option)\u001b[0m\n\u001b[1;32m    407\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m             \u001b[0;32mimport\u001b[0m \u001b[0mfugashi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mModuleNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'fugashi'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-3097287974>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;31m# ========================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"cl-tohoku/bert-base-japanese-v2\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtokenize_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/tokenization_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1011\u001b[0m                     \u001b[0;34mf\"Tokenizer class {tokenizer_class_candidate} does not exist or is not currently imported.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m                 )\n\u001b[0;32m-> 1013\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m         \u001b[0;31m# Otherwise we have to be creative.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2023\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"loading file {file_path} from cache at {resolved_vocab_files[file_id]}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2024\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2025\u001b[0;31m         return cls._from_pretrained(\n\u001b[0m\u001b[1;32m   2026\u001b[0m             \u001b[0mresolved_vocab_files\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2027\u001b[0m             \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m_from_pretrained\u001b[0;34m(cls, resolved_vocab_files, pretrained_model_name_or_path, init_configuration, token, cache_dir, local_files_only, _commit_hash, _is_local, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2276\u001b[0m         \u001b[0;31m# Instantiate the tokenizer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2277\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2278\u001b[0;31m             \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minit_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2279\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mimport_protobuf_decode_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2280\u001b[0m             logger.info(\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert_japanese/tokenization_bert_japanese.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, vocab_file, spm_file, do_lower_case, do_word_tokenize, do_subword_tokenize, word_tokenizer_type, subword_tokenizer_type, never_split, unk_token, sep_token, pad_token, cls_token, mask_token, mecab_kwargs, sudachi_kwargs, jumanpp_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m                 )\n\u001b[1;32m    142\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mword_tokenizer_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"mecab\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m                 self.word_tokenizer = MecabTokenizer(\n\u001b[0m\u001b[1;32m    144\u001b[0m                     \u001b[0mdo_lower_case\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdo_lower_case\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnever_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnever_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmecab_kwargs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m                 )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert_japanese/tokenization_bert_japanese.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, do_lower_case, never_split, normalize_text, mecab_dic, mecab_option)\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mfugashi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mModuleNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m             raise error.__class__(\n\u001b[0m\u001b[1;32m    411\u001b[0m                 \u001b[0;34m\"You need to install fugashi to use MecabTokenizer. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m                 \u001b[0;34m\"See https://pypi.org/project/fugashi/ for installation.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: You need to install fugashi to use MecabTokenizer. See https://pypi.org/project/fugashi/ for installation.","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.metrics import classification_report\n","from sklearn.model_selection import train_test_split\n","from xgboost import XGBClassifier\n","from sklearn.preprocessing import LabelEncoder\n","import optuna\n","from sklearn.pipeline import Pipeline\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from ace_tools_open import display_dataframe_to_user\n","\n","# Use the existing validated dataframe (df_valid from earlier)\n","df_valid_sample = df_valid.copy()\n","df_valid_sample['predicted'] = df_valid_sample['text'].apply(predict_sentiment)\n","df_valid_sample['kansai_ben'] = df_valid_sample['text'].apply(detect_kansaiben)\n","df_valid_sample['direct_tone'] = df_valid_sample['text'].apply(detect_directness)\n","\n","# Encode labels\n","le = LabelEncoder()\n","df_valid_sample['sentiment_label'] = le.fit_transform(df_valid_sample['sentiment'])\n","df_valid_sample['predicted_label'] = le.transform([[\"Negative\", \"Neutral\", \"Positive\"].index(x) for x in df_valid_sample['predicted']])\n","\n","# Define Optuna objective for XGBoost\n","def objective(trial):\n","    params = {\n","        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n","        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.3),\n","        \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 300),\n","        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n","        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n","        \"use_label_encoder\": False,\n","        \"eval_metric\": \"mlogloss\"\n","    }\n","\n","    X_train, X_test, y_train, y_test = train_test_split(\n","        df_valid_sample['text'], df_valid_sample['sentiment_label'], test_size=0.2, random_state=42\n","    )\n","\n","    pipeline = Pipeline([\n","        ('tfidf', TfidfVectorizer(max_features=3000)),\n","        ('clf', XGBClassifier(**params))\n","    ])\n","\n","    pipeline.fit(X_train, y_train)\n","    return pipeline.score(X_test, y_test)\n","\n","# Run Optuna optimization\n","study = optuna.create_study(direction=\"maximize\")\n","study.optimize(objective, n_trials=15)\n","\n","# Train final model with best parameters\n","best_params = study.best_params\n","best_params[\"use_label_encoder\"] = False\n","best_params[\"eval_metric\"] = \"mlogloss\"\n","final_model = Pipeline([\n","    ('tfidf', TfidfVectorizer(max_features=3000)),\n","    ('clf', XGBClassifier(**best_params))\n","])\n","final_model.fit(df_valid_sample['text'], df_valid_sample['sentiment_label'])\n","\n","# Predict and evaluate\n","df_valid_sample['xgb_pred'] = final_model.predict(df_valid_sample['text'])\n","report = classification_report(df_valid_sample['sentiment_label'], df_valid_sample['xgb_pred'], target_names=le.classes_, output_dict=True)\n","report_df = pd.DataFrame(report).transpose()\n","\n","# Display results\n","display_dataframe_to_user(name=\"JGLUE Sentiment Validation with XGBoost\", dataframe=df_valid_sample)\n","report_df.head()\n"],"metadata":{"id":"97T1pwXG-YPl"},"execution_count":null,"outputs":[]}]}